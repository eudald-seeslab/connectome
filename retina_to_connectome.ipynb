{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:19.224308908Z",
     "start_time": "2024-02-26T17:15:16.774680183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from adult_models_helpers import get_synapse_df\n",
    "from flyvis.examples.flyvision_ans import DECODING_CELLS\n",
    "from graph_models import GNNModel\n",
    "from retina_to_connectome import get_activation_tensor, get_batch_voronoi_averages, voronoi_averages_to_df\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "last_good_frame = 8"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get data\n",
    "activations_dir = \"flyvis/parsed_objects\"\n",
    "activations = np.load(os.path.join(activations_dir, \"decoding_activations.npy\"), allow_pickle=True)\n",
    "# labels = np.load(os.path.join(activations_dir, \"decoding_labels.npy\"), allow_pickle=True)\n",
    "# toy labels as a tensor with all 1\n",
    "labels = torch.ones(activations.shape[0], dtype=torch.long, device=DEVICE)\n",
    "classification = pd.read_csv(\"adult_data/classification.csv\")\n",
    "\n",
    "# remove duplicated root_ids\n",
    "classification = classification.drop_duplicates(subset='root_id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:22.888350676Z",
     "start_time": "2024-02-26T17:15:20.979484729Z"
    }
   },
   "id": "a1466ccb6d444b07",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:12<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "avgs_dict = {}\n",
    "for cell_type in tqdm(DECODING_CELLS):\n",
    "    number_of_cells = len(classification[classification[\"cell_type\"] == cell_type])\n",
    "    if number_of_cells > 0:\n",
    "        activation_tensor = get_activation_tensor(activations, cell_type, last_frame=last_good_frame) / 255\n",
    "        avgs_dict[cell_type] = get_batch_voronoi_averages(activation_tensor, n_centers=number_of_cells)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:35.567202870Z",
     "start_time": "2024-02-26T17:15:22.893212273Z"
    }
   },
   "id": "8a91bc55a5c9604c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result_df = voronoi_averages_to_df(avgs_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:35.595337153Z",
     "start_time": "2024-02-26T17:15:35.566267154Z"
    }
   },
   "id": "66d6df94b20c7524",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract cell types and activations\n",
    "cell_types = result_df.iloc[:, -1]  # Last column for cell type\n",
    "activations = result_df.iloc[:, :-1]  # Exclude the last column\n",
    "\n",
    "# Create a dictionary to hold shuffled root_ids for each cell type\n",
    "root_id_mapping = {}\n",
    "\n",
    "# Populate the dictionary with shuffled root_ids for each cell type\n",
    "for cell_type, group in classification.groupby(\"cell_type\"):\n",
    "    # Shuffle the root_ids within each group\n",
    "    shuffled_root_ids = group['root_id'].sample(frac=1).values\n",
    "    root_id_mapping[cell_type] = shuffled_root_ids\n",
    "\n",
    "# Function to assign root_ids to each row in result_df based on cell type and available root_ids\n",
    "def assign_root_ids(row):\n",
    "    cell_type = row.iloc[-1]  # Get cell type from the last column\n",
    "    # Get the list of shuffled root_ids for this cell type\n",
    "    root_ids = root_id_mapping[cell_type]\n",
    "    # Assign a root_id from the list, ensuring we don't exceed the list's length\n",
    "    # The index in the list is the count of occurrences of this cell type so far, modulo the number of available root_ids\n",
    "    root_id_index = row.name % len(root_ids)  # row.name is the index of the row in the dataframe\n",
    "    return root_ids[root_id_index]\n",
    "\n",
    "# Apply the function to result_df, creating a new 'root_id' column\n",
    "result_df['root_id'] = result_df.apply(assign_root_ids, axis=1)\n",
    "\n",
    "# Remove duplicated root_ids\n",
    "result_df = result_df.drop_duplicates(subset='root_id')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:36.459100779Z",
     "start_time": "2024-02-26T17:15:35.589603627Z"
    }
   },
   "id": "aa33a3309a235441",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = pd.merge(\n",
    "    classification.drop(\n",
    "        columns=[\"flow\", \"super_class\", \"class\", \"sub_class\", \n",
    "                 \"hemibrain_type\", \"hemilineage\", \"side\", \"nerve\"]), \n",
    "    result_df.drop(columns=[result_df.columns[-2]]), on='root_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:36.596788013Z",
     "start_time": "2024-02-26T17:15:36.461256942Z"
    }
   },
   "id": "7b9d37652bf3d75a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "synapse_df = get_synapse_df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:38.662358733Z",
     "start_time": "2024-02-26T17:15:36.598988811Z"
    }
   },
   "id": "ea5873de3ea67ca8",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: Identify Common Neurons\n",
    "# Unique root_ids in merged_df\n",
    "neurons_merged = pd.unique(activation_df['root_id'])\n",
    "\n",
    "# Unique root_ids in synapse_df (both pre and post)\n",
    "neurons_synapse_pre = pd.unique(synapse_df['pre_root_id'])\n",
    "neurons_synapse_post = pd.unique(synapse_df['post_root_id'])\n",
    "neurons_synapse = np.unique(np.concatenate([neurons_synapse_pre, neurons_synapse_post]))\n",
    "\n",
    "# Common neurons\n",
    "common_neurons = np.intersect1d(neurons_merged, neurons_synapse)\n",
    "\n",
    "# Step 2: Filter synapse_df\n",
    "# Keep only rows with both pre and post root_ids in common_neurons\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Filter synapse_df to include only rows with both pre and post root_ids in common_neurons\n",
    "filtered_synapse_df = synapse_df[\n",
    "    synapse_df['pre_root_id'].isin(common_neurons) & synapse_df['post_root_id'].isin(common_neurons)\n",
    "]\n",
    "\n",
    "# Map neuron root_ids to matrix indices\n",
    "root_id_to_index = {root_id: index for index, root_id in enumerate(common_neurons)}\n",
    "\n",
    "# Convert root_ids in filtered_synapse_df to matrix indices\n",
    "pre_indices = filtered_synapse_df['pre_root_id'].map(root_id_to_index).values\n",
    "post_indices = filtered_synapse_df['post_root_id'].map(root_id_to_index).values\n",
    "\n",
    "# Use syn_count as the data for the non-zero elements of the matrix\n",
    "data = filtered_synapse_df['syn_count'].values\n",
    "\n",
    "# Create a sparse matrix in COO format\n",
    "synaptic_matrix_sparse = coo_matrix(\n",
    "    (data, (pre_indices, post_indices)),\n",
    "    shape=(len(common_neurons), len(common_neurons)),\n",
    "    dtype=np.int64  # or np.float32/np.float64 if memory issue persists\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:39.632483492Z",
     "start_time": "2024-02-26T17:15:38.667789289Z"
    }
   },
   "id": "4b9b0fc3eb3b1c75",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = activation_df[activation_df['root_id'].isin(list(root_id_to_index.keys()))]\n",
    "activation_data = activation_df.drop(columns=[\"root_id\", \"cell_type\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:39.690708380Z",
     "start_time": "2024-02-26T17:15:39.645937496Z"
    }
   },
   "id": "ac4670dc90dd0a2c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "5467"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the info from data/cell_type_rational.csv\n",
    "cell_type_rational = pd.read_csv(\"data/cell_type_rational.csv\")\n",
    "# get the cell types with rational = 1\n",
    "rational_cell_types = cell_type_rational[cell_type_rational[\"rational\"] == 1][\"cell_type\"]\n",
    "# find, using the root to index dictionary, the indices of the rational cells\n",
    "rational_indices = [root_id_to_index[root_id] for root_id in activation_df[activation_df[\"cell_type\"].isin(rational_cell_types)][\"root_id\"]]\n",
    "len(rational_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T16:51:32.717684793Z",
     "start_time": "2024-02-26T16:51:32.693136466Z"
    }
   },
   "id": "a3e7f859efdb998e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16155/1233677983.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  edges = torch.tensor([synaptic_matrix_sparse.row, synaptic_matrix_sparse.col], dtype=torch.long, device=DEVICE)\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacty of 7.58 GiB of which 1.43 GiB is free. Including non-PyTorch memory, this process has 5.99 GiB memory in use. Of the allocated memory 4.79 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 29>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(device_type):\n\u001B[0;32m---> 35\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out, batch\u001B[38;5;241m.\u001B[39my)    \n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Backward pass and optimize\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/graph_models.py:21\u001B[0m, in \u001B[0;36mGNNModel.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     19\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x, edge_index))\n\u001B[1;32m     20\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(x, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[0;32m---> 21\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Global pooling\u001B[39;00m\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m global_mean_pool(x, batch)  \u001B[38;5;66;03m# Pool node features to the graph level\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:244\u001B[0m, in \u001B[0;36mGCNConv.forward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m    241\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(x)\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[0;32m--> 244\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m                     \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    248\u001B[0m     out \u001B[38;5;241m=\u001B[39m out \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:463\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[0;32m--> 463\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m    465\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:253\u001B[0m, in \u001B[0;36mGCNConv.message\u001B[0;34m(self, x_j, edge_weight)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_j: Tensor, edge_weight: OptTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 253\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j \u001B[38;5;28;01mif\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_j\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 4.78 GiB. GPU 0 has a total capacty of 7.58 GiB of which 1.43 GiB is free. Including non-PyTorch memory, this process has 5.99 GiB memory in use. Of the allocated memory 4.79 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device_type = \"cpu\" # for debugging\n",
    "DEVICE = torch.device(device_type)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "edges = torch.tensor([synaptic_matrix_sparse.row, synaptic_matrix_sparse.col], dtype=torch.long, device=DEVICE)\n",
    "activation_tensor = torch.tensor(activation_data.values, dtype=torch.float16, device=DEVICE)\n",
    "\n",
    "# Correctly set node features for each graph\n",
    "graph_list = []\n",
    "for i in range(activation_tensor.shape[1]):  # Iterate over samples, ensuring the second dimension is the sample dimension\n",
    "    node_features = activation_tensor[:, i].unsqueeze(1)  # Shape [num_nodes, 1], one feature per node\n",
    "    graph = Data(x=node_features.to(DEVICE), edge_index=edges, y=labels[i])  # Create a graph for each sample\n",
    "    graph_list.append(graph)\n",
    "\n",
    "# DataLoader to handle batches of graphs\n",
    "loader = DataLoader(graph_list, batch_size=10, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = GNNModel(num_node_features=1, num_classes=2).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for batch_idx, batch in tqdm(enumerate(loader)):\n",
    "    batch = batch.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast(device_type):\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T17:15:41.360918850Z",
     "start_time": "2024-02-26T17:15:40.481520676Z"
    }
   },
   "id": "4f726ab91ee1f4cb",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "1. Literature review to identify the \"thinking\" neurons\n",
    "2. Identify these neurons in the classification dataframe and create a class_labels tensor\n",
    "3. Train the model with the class_labels tensor\n",
    "4. Check model accuracy and weber ratio\n",
    "5. Try with other model architectures, specially with a one-hot encoding for each neuron type to simulate different neurons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acc97de0c76463cf"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36fda2cb163b38ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kenyon Cells (KC): KCab, KCapbp-m, KCapbp-ap1, KCapbp-ap2\n",
    "T4/T5 Neurons: These are involved in motion detection and possibly could be implicated in processing visual information related to numerosity. The neurons you've listed include T4a, T4b, T4c, T4d, T5a, T5b, T5c, T5d.\n",
    "Central Complex Neurons: These are involved in a variety of integrative brain functions which could include decision-making processes. The neurons from your list include C2, C3."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fff1d4f4edf4fe8d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36647724373c0ba1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

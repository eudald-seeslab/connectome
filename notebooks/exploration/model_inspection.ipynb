{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi, cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "\n",
    "cmap = plt.cm.binary\n",
    "\n",
    "from configs import config\n",
    "from connectome.core.data_processing import DataProcessor\n",
    "from connectome.core.graph_models import FullGraphModel\n",
    "from connectome.core.train_funcs import get_activation_from_cell_type, assign_cell_type\n",
    "from utils.model_inspection_utils import process_image, process_and_plot_data\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor(config)\n",
    "model = FullGraphModel(data_processor, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_connections(connections, filtered_neurons):\n",
    "    both_filtered = connections[\n",
    "        connections[\"pre_root_id\"].isin(filtered_neurons)\n",
    "        & connections[\"post_root_id\"].isin(filtered_neurons)\n",
    "    ]\n",
    "\n",
    "    one_filtered = connections[\n",
    "        (\n",
    "            connections[\"pre_root_id\"].isin(filtered_neurons)\n",
    "            ^ connections[\"post_root_id\"].isin(filtered_neurons)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    none_filtered = connections[\n",
    "        ~connections[\"pre_root_id\"].isin(filtered_neurons)\n",
    "        & ~connections[\"post_root_id\"].isin(filtered_neurons)\n",
    "    ]\n",
    "\n",
    "    print(\"\\nConnection Analysis:\")\n",
    "    print(f\"Both neurons filtered: {len(both_filtered)}\")\n",
    "    print(f\"One neuron filtered: {len(one_filtered)}\")\n",
    "    print(f\"No neurons filtered: {len(none_filtered)}\")\n",
    "\n",
    "    return both_filtered, one_filtered, none_filtered\n",
    "\n",
    "original_neurons = data_processor._get_neurons(new_connectome=True)\n",
    "filtered_celltypes = config.filtered_celltypes\n",
    "connections = data_processor._get_connections(new_connectome=True)\n",
    "\n",
    "\n",
    "# Use it like this\n",
    "filtered_neurons = set(\n",
    "    original_neurons[original_neurons[\"cell_type\"].isin(filtered_celltypes)][\"root_id\"]\n",
    ")\n",
    "both, one, none = analyze_connections(connections, filtered_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/m_2024-12-27_10:44_d0ejaj1i.pth\", map_location=\"cpu\")\n",
    "if \"root_ids\" in checkpoint:\n",
    "    print(\"\\nCheckpoint has root_ids information\")\n",
    "# You might also want to check other keys that could contain this info\n",
    "print(\"All checkpoint keys:\", list(checkpoint.keys()))\n",
    "if \"model\" in checkpoint:\n",
    "    print(\"Model state dict keys:\", list(checkpoint[\"model\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/m_2024-12-27_10:44_d0ejaj1i.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "connections = (\n",
    "    pd.read_csv(\n",
    "        \"new_data/connections.csv\",\n",
    "        dtype={\n",
    "            \"pre_root_id\": \"string\",\n",
    "            \"post_root_id\": \"string\",\n",
    "            \"syn_count\": np.int32,\n",
    "        },\n",
    "    )\n",
    "    .groupby([\"pre_root_id\", \"post_root_id\"])\n",
    "    .sum(\"syn_count\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "connections[\"weight\"] = model.connectome.edge_weight_multiplier.detach()\n",
    "right_root_ids = data_processor.right_root_ids\n",
    "all_neurons = (\n",
    "    pd.read_csv(\"new_data/classification.csv\")\n",
    "    .merge(right_root_ids, on=\"root_id\")\n",
    "    .fillna(\"Unknown\")\n",
    ")\n",
    "right_visual_neurons = data_processor.voronoi_cells.get_tesselated_neurons().merge(\n",
    "    right_root_ids, on=\"root_id\"\n",
    ")\n",
    "neuron_data = pd.read_csv(\n",
    "    \"new_data/right_visual_positions_selected_neurons.csv\",\n",
    "    dtype={\"root_id\": \"string\"},\n",
    ").drop(columns=[\"x\", \"y\", \"z\", \"PC1\", \"PC2\"])\n",
    "data_cols = [\"x_axis\", \"y_axis\"]\n",
    "decision_making_vector = data_processor.decision_making_vector\n",
    "all_coords = pd.read_csv(\"../../adult_data/all_coords_clean.csv\", dtype={\"root_id\": \"string\"})\n",
    "rational_cell_types = pd.read_csv(\"../../adult_data/rational_cell_types.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesselation propagation\n",
    "centers = neuron_data[neuron_data[\"cell_type\"] == \"R7\"][data_cols].values\n",
    "voronoi = Voronoi(centers)\n",
    "tree = cKDTree(centers)\n",
    "neuron_indices = tree.query(neuron_data[data_cols].values)[1]\n",
    "neuron_data[\"voronoi_indices\"] = neuron_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(\"images/five_to_fifteen/train/yellow/img_12_8_174_equalized_.png\")\n",
    "processed_image = process_image(img, tree)\n",
    "neuron_data = neuron_data.merge(processed_image, left_on=\"voronoi_indices\", right_index=True)\n",
    "neuron_data[\"cell_type\"] = neuron_data.apply(assign_cell_type, axis=1)\n",
    "neuron_data[\"activation\"] = neuron_data.apply(get_activation_from_cell_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "tplot = process_and_plot_data(img, neuron_data, connections, voronoi, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = CompleteModelsDataProcessor(config)\n",
    "\n",
    "# Print key information about the synaptic matrix\n",
    "print(f\"Synaptic matrix shape: {data_processor.synaptic_matrix.shape}\")\n",
    "print(f\"Number of non-zero elements: {data_processor.synaptic_matrix.nnz}\")\n",
    "print(f\"First 5 row indices: {data_processor.synaptic_matrix.row[:5]}\")\n",
    "print(f\"First 5 col indices: {data_processor.synaptic_matrix.col[:5]}\")\n",
    "print(f\"First 5 data values: {data_processor.synaptic_matrix.data[:5]}\")\n",
    "\n",
    "# Print information about the root IDs\n",
    "print(f\"Number of root IDs: {len(data_processor.root_ids)}\")\n",
    "print(f\"First 5 root IDs: {data_processor.root_ids['root_id'].iloc[:5]}\")\n",
    "\n",
    "# Print edge information from the model\n",
    "print(f\"Edge index shape: {data_processor.edges.shape}\")\n",
    "print(f\"Edge weights shape: {data_processor.weights.shape}\")\n",
    "\n",
    "print(\"Configuration check:\")\n",
    "print(f\"filtered_celltypes: {config.filtered_celltypes}\")\n",
    "print(f\"neurons: {config.neurons}\")\n",
    "print(f\"voronoi_criteria: {config.voronoi_criteria}\")\n",
    "print(f\"new_connectome: {config.new_connectome}\")\n",
    "print(f\"refined_synaptic_data: {config.refined_synaptic_data}\")\n",
    "print(f\"eye: {config.eye}\")\n",
    "print(f\"rational_cell_types: {config.rational_cell_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_synaptic_matrix(matrix, previous_state=None):\n",
    "    \"\"\"\n",
    "    Validates a synaptic matrix for consistency and returns key metrics for comparison.\n",
    "    \n",
    "    Args:\n",
    "        matrix: The sparse matrix to validate \n",
    "        previous_state: Optional dict with previous metrics to compare against\n",
    "    \n",
    "    Returns:\n",
    "        dict: Metrics about the matrix\n",
    "    \"\"\"\n",
    "    # Get key metrics\n",
    "    metrics = {\n",
    "        \"shape\": matrix.shape,\n",
    "        \"nnz\": matrix.nnz,\n",
    "        \"min_weight\": float(matrix.data.min()),\n",
    "        \"max_weight\": float(matrix.data.max()),\n",
    "        \"mean_weight\": float(matrix.data.mean()),\n",
    "        \"zero_values\": int((np.abs(matrix.data) < 1e-10).sum()),\n",
    "        \"unique_values\": len(np.unique(matrix.data))\n",
    "    }\n",
    "    \n",
    "    # Compare with previous if provided\n",
    "    if previous_state:\n",
    "        differences = []\n",
    "        for key in metrics:\n",
    "            if metrics[key] != previous_state[key]:\n",
    "                differences.append(f\"{key}: {previous_state[key]} -> {metrics[key]}\")\n",
    "        \n",
    "        if differences:\n",
    "            print(\"WARNING: Matrix metrics changed:\")\n",
    "            for diff in differences:\n",
    "                print(f\"  {diff}\")\n",
    "        else:\n",
    "            print(\"Matrix metrics consistent with previous state\")\n",
    "            \n",
    "    return metrics\n",
    "\n",
    "# Usage example:\n",
    "state = None\n",
    "def check_matrix_consistency():\n",
    "    global state\n",
    "    \n",
    "    # Create processor and get matrix\n",
    "    data_processor = DataProcessor(config)\n",
    "    \n",
    "    # Validate matrix\n",
    "    new_state = validate_synaptic_matrix(data_processor.synaptic_matrix, state)\n",
    "    \n",
    "    # Store for next comparison\n",
    "    state = new_state\n",
    "    \n",
    "    return data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run\n",
    "processor1 = check_matrix_consistency()\n",
    "\n",
    "# Second run\n",
    "processor2 = check_matrix_consistency()  # Should show \"Matrix metrics consistent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:14.174013Z",
     "start_time": "2024-03-01T10:36:11.455681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autocast, device, cuda\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from adult_models_helpers import get_synapse_df\n",
    "from flyvis.examples.flyvision_ans import DECODING_CELLS\n",
    "from graph_models import GNNModel\n",
    "from retina_to_connectome import get_activation_tensor, get_batch_voronoi_averages, voronoi_averages_to_df\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "last_good_frame = 8"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get data\n",
    "activations_dir = \"flyvis/parsed_objects\"\n",
    "activations = np.load(os.path.join(activations_dir, \"decoding_activations.npy\"), allow_pickle=True)\n",
    "# labels = np.load(os.path.join(activations_dir, \"decoding_labels.npy\"), allow_pickle=True)\n",
    "# toy labels as a tensor with all 1\n",
    "labels = torch.ones(activations.shape[0], dtype=torch.long, device=DEVICE)\n",
    "classification = pd.read_csv(\"adult_data/classification.csv\")\n",
    "\n",
    "# remove duplicated root_ids\n",
    "classification = classification.drop_duplicates(subset='root_id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:15.983381Z",
     "start_time": "2024-03-01T10:36:14.175406Z"
    }
   },
   "id": "a1466ccb6d444b07",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:11<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "avgs_dict = {}\n",
    "for cell_type in tqdm(DECODING_CELLS):\n",
    "    number_of_cells = len(classification[classification[\"cell_type\"] == cell_type])\n",
    "    if number_of_cells > 0:\n",
    "        activation_tensor = get_activation_tensor(activations, cell_type, last_frame=last_good_frame) / 255\n",
    "        avgs_dict[cell_type] = get_batch_voronoi_averages(activation_tensor, n_centers=number_of_cells)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:27.307990Z",
     "start_time": "2024-03-01T10:36:15.984667Z"
    }
   },
   "id": "8a91bc55a5c9604c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result_df = voronoi_averages_to_df(avgs_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:27.329607Z",
     "start_time": "2024-03-01T10:36:27.310020Z"
    }
   },
   "id": "66d6df94b20c7524",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract cell types and activations\n",
    "cell_types = result_df.iloc[:, -1]  # Last column for cell type\n",
    "activations = result_df.iloc[:, :-1]  # Exclude the last column\n",
    "\n",
    "# Create a dictionary to hold shuffled root_ids for each cell type\n",
    "root_id_mapping = {}\n",
    "\n",
    "# Populate the dictionary with shuffled root_ids for each cell type\n",
    "for cell_type, group in classification.groupby(\"cell_type\"):\n",
    "    # Shuffle the root_ids within each group\n",
    "    shuffled_root_ids = group['root_id'].sample(frac=1).values\n",
    "    root_id_mapping[cell_type] = shuffled_root_ids\n",
    "\n",
    "# Function to assign root_ids to each row in result_df based on cell type and available root_ids\n",
    "def assign_root_ids(row):\n",
    "    cell_type = row.iloc[-1]  # Get cell type from the last column\n",
    "    # Get the list of shuffled root_ids for this cell type\n",
    "    root_ids = root_id_mapping[cell_type]\n",
    "    # Assign a root_id from the list, ensuring we don't exceed the list's length\n",
    "    # The index in the list is the count of occurrences of this cell type so far, modulo the number of available root_ids\n",
    "    root_id_index = row.name % len(root_ids)  # row.name is the index of the row in the dataframe\n",
    "    return root_ids[root_id_index]\n",
    "\n",
    "# Apply the function to result_df, creating a new 'root_id' column\n",
    "result_df['root_id'] = result_df.apply(assign_root_ids, axis=1)\n",
    "\n",
    "# Remove duplicated root_ids\n",
    "result_df = result_df.drop_duplicates(subset='root_id')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:28.267401Z",
     "start_time": "2024-03-01T10:36:27.330439Z"
    }
   },
   "id": "aa33a3309a235441",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = pd.merge(\n",
    "    classification.drop(\n",
    "        columns=[\"flow\", \"super_class\", \"class\", \"sub_class\", \n",
    "                 \"hemibrain_type\", \"hemilineage\", \"side\", \"nerve\"]), \n",
    "    result_df.drop(columns=[result_df.columns[-2]]), on='root_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:28.437682Z",
     "start_time": "2024-03-01T10:36:28.268427Z"
    }
   },
   "id": "7b9d37652bf3d75a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "synapse_df = get_synapse_df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:30.900763Z",
     "start_time": "2024-03-01T10:36:28.439063Z"
    }
   },
   "id": "ea5873de3ea67ca8",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: Identify Common Neurons\n",
    "# Unique root_ids in merged_df\n",
    "neurons_merged = pd.unique(activation_df['root_id'])\n",
    "\n",
    "# Unique root_ids in synapse_df (both pre and post)\n",
    "neurons_synapse_pre = pd.unique(synapse_df['pre_root_id'])\n",
    "neurons_synapse_post = pd.unique(synapse_df['post_root_id'])\n",
    "neurons_synapse = np.unique(np.concatenate([neurons_synapse_pre, neurons_synapse_post]))\n",
    "\n",
    "# Common neurons\n",
    "common_neurons = np.intersect1d(neurons_merged, neurons_synapse)\n",
    "\n",
    "# Step 2: Filter synapse_df\n",
    "# Keep only rows with both pre and post root_ids in common_neurons\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Filter synapse_df to include only rows with both pre and post root_ids in common_neurons\n",
    "filtered_synapse_df = synapse_df[\n",
    "    synapse_df['pre_root_id'].isin(common_neurons) & synapse_df['post_root_id'].isin(common_neurons)\n",
    "]\n",
    "\n",
    "# Map neuron root_ids to matrix indices\n",
    "root_id_to_index = {root_id: index for index, root_id in enumerate(common_neurons)}\n",
    "\n",
    "# Convert root_ids in filtered_synapse_df to matrix indices\n",
    "pre_indices = filtered_synapse_df['pre_root_id'].map(root_id_to_index).values\n",
    "post_indices = filtered_synapse_df['post_root_id'].map(root_id_to_index).values\n",
    "\n",
    "# Use syn_count as the data for the non-zero elements of the matrix\n",
    "data = filtered_synapse_df['syn_count'].values\n",
    "\n",
    "# Create a sparse matrix in COO format\n",
    "synaptic_matrix_sparse = coo_matrix(\n",
    "    (data, (pre_indices, post_indices)),\n",
    "    shape=(len(common_neurons), len(common_neurons)),\n",
    "    dtype=np.int64  # or np.float32/np.float64 if memory issue persists\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:32.064748Z",
     "start_time": "2024-03-01T10:36:30.901676Z"
    }
   },
   "id": "4b9b0fc3eb3b1c75",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = activation_df[activation_df['root_id'].isin(list(root_id_to_index.keys()))]\n",
    "activation_data = activation_df.drop(columns=[\"root_id\", \"cell_type\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:32.132468Z",
     "start_time": "2024-03-01T10:36:32.065848Z"
    }
   },
   "id": "ac4670dc90dd0a2c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get the info from data/cell_type_rational.csv\n",
    "cell_type_rational = pd.read_csv(\"data/cell_type_rational.csv\")\n",
    "# get the cell types with rational = 1\n",
    "rational_cell_types = cell_type_rational[cell_type_rational[\"rational\"] == 1][\"cell_type\"]\n",
    "# find, using the root to index dictionary, the indices of the rational cells\n",
    "rational_indices = [root_id_to_index[root_id] for root_id in activation_df[activation_df[\"cell_type\"].isin(rational_cell_types)][\"root_id\"]]\n",
    "decision_making_vector = np.zeros(activation_df.shape[0], dtype=int)\n",
    "decision_making_vector[rational_indices] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:32.163439Z",
     "start_time": "2024-03-01T10:36:32.133943Z"
    }
   },
   "id": "a3e7f859efdb998e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "edges = torch.tensor(np.array([synaptic_matrix_sparse.row, synaptic_matrix_sparse.col]), dtype=torch.long, device=DEVICE)\n",
    "activation_tensor = torch.tensor(activation_data.values, dtype=torch.float16, device=DEVICE)\n",
    "\n",
    "# move the decision-making vector to the device\n",
    "decision_making_vector = torch.tensor(decision_making_vector, dtype=torch.float16, device=DEVICE).detach()\n",
    "\n",
    "# Correctly set node features for each graph\n",
    "graph_list = []\n",
    "for i in range(activation_tensor.shape[1]):  # Iterate over samples, ensuring the second dimension is the sample dimension\n",
    "    node_features = activation_tensor[:, i].unsqueeze(1)  # Shape [num_nodes, 1], one feature per node\n",
    "    graph = Data(x=node_features.to(DEVICE), edge_index=edges, y=labels[i])  # Create a graph for each sample\n",
    "    graph_list.append(graph)\n",
    "\n",
    "# DataLoader to handle batches of graphs\n",
    "loader = DataLoader(graph_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = GNNModel(num_node_features=1, decision_making_vector=decision_making_vector).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "model.train()\n",
    "for batch_idx, batch in tqdm(enumerate(loader)):\n",
    "    batch = batch.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast(device_type):\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y.unsqueeze(-1).float())    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:36:33.200922Z",
     "start_time": "2024-03-01T10:36:32.164733Z"
    }
   },
   "id": "4f726ab91ee1f4cb",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "1. Literature review to identify the \"thinking\" neurons\n",
    "2. Identify these neurons in the classification dataframe and create a class_labels tensor\n",
    "3. Train the model with the class_labels tensor\n",
    "4. Check model accuracy and weber ratio\n",
    "5. Try with other model architectures, specially with a one-hot encoding for each neuron type to simulate different neurons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acc97de0c76463cf"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36fda2cb163b38ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kenyon Cells (KC): KCab, KCapbp-m, KCapbp-ap1, KCapbp-ap2\n",
    "T4/T5 Neurons: These are involved in motion detection and possibly could be implicated in processing visual information related to numerosity. The neurons you've listed include T4a, T4b, T4c, T4d, T5a, T5b, T5c, T5d.\n",
    "Central Complex Neurons: These are involved in a variety of integrative brain functions which could include decision-making processes. The neurons from your list include C2, C3.\n",
    "torch.unique(batch.y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b841d74ff7cc601"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:04:46.941314Z",
     "start_time": "2024-03-01T09:04:46.937250Z"
    }
   },
   "id": "30a10e83166f413c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:05:14.205394Z",
     "start_time": "2024-03-01T09:05:14.201268Z"
    }
   },
   "id": "53aef8a6447394d7",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "df78fe0069fea8df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

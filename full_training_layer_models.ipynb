{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:40:02.816615Z",
     "start_time": "2024-03-28T14:39:58.709963Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import device, cuda, autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from random import sample\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "import flyvision\n",
    "from flyvision_ans import DECODING_CELLS\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "from from_image_to_video import image_paths_to_sequences\n",
    "from from_retina_to_connectome_funcs import from_retina_to_model, get_cell_type_indices, compute_voronoi_averages, from_retina_to_connectome\n",
    "from logs_to_wandb import log_images_to_wandb, log_running_stats_to_wandb\n",
    "from from_video_to_training_batched_funcs import get_files_from_directory, select_random_videos, paths_to_labels, \\\n",
    "    load_custom_sequences\n",
    "from from_retina_to_connectome_utils import hex_to_square_grid, initialize_results_df, predictions_and_corrects_from_model_results, update_results_df, update_running_loss, get_decision_making_neurons\n",
    "from adult_models import FullAdultModel\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    'ignore',\n",
    "    message='invalid value encountered in cast',\n",
    "    category=RuntimeWarning,\n",
    "    module='wandb.sdk.data_types.image'\n",
    ")\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "dtype = torch.float32\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "#device_type = \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "\n",
    "TRAINING_DATA_DIR = \"images/easy_v2\"\n",
    "TESTING_DATA_DIR = \"images/easy_images\"\n",
    "VALIDATION_DATA_DIR = \"images/easyval_images\"\n",
    "\n",
    "debugging = True\n",
    "debug_length = 20\n",
    "wandb_ = False\n",
    "wandb_images_every = 100\n",
    "small = True\n",
    "small_length = 2000\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "\n",
    "dropout = .1\n",
    "max_lr = 0.01\n",
    "base_lr = 0.001\n",
    "weight_decay = 0.0001\n",
    "NUM_CONNECTOME_PASSES=5\n",
    "\n",
    "use_one_cycle_lr = False\n",
    "\n",
    "model_config = {\n",
    "    \"debugging\": debugging,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dropout\": dropout,\n",
    "    \"base_lr\": base_lr,\n",
    "    \"max_lr\": max_lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"num_connectome_passes\": NUM_CONNECTOME_PASSES,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b101e44d143f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:18:59.226154Z",
     "start_time": "2024-03-28T14:18:54.651619Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init stuff\n",
    "extent, kernel_size = 15, 13\n",
    "decision_making_vector = get_decision_making_neurons(dtype).to(DEVICE)\n",
    "receptors = flyvision.rendering.BoxEye(extent=extent, kernel_size=kernel_size)\n",
    "network_view = flyvision.NetworkView(flyvision.results_dir / \"opticflow/000/0000\")\n",
    "network = network_view.init_network(chkpt=\"best_chkpt\")\n",
    "classification = pd.read_csv(\"adult_data/classification_clean.csv\")\n",
    "root_id_to_index = pd.read_csv(\"adult_data/root_id_to_index.csv\")\n",
    "dt = 1 / 100 # some parameter from flyvision\n",
    "last_good_frame = 2\n",
    "cell_type_plot = \"TmY18\"\n",
    "\n",
    "cell_type_indices = get_cell_type_indices(classification, root_id_to_index, DECODING_CELLS)\n",
    "\n",
    "training_videos = get_files_from_directory(TRAINING_DATA_DIR)\n",
    "test_videos = get_files_from_directory(TESTING_DATA_DIR)\n",
    "validation_videos = get_files_from_directory(TESTING_DATA_DIR)\n",
    "\n",
    "if small:\n",
    "    training_videos = sample(training_videos, small_length)\n",
    "    test_videos = sample(test_videos, small_length)\n",
    "    validation_videos = sample(validation_videos, int(small_length / 5))\n",
    "\n",
    "if len(training_videos) == 0:\n",
    "    print(\"I can't find any training images or videos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fce80a3502cf3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:18:59.238988Z",
     "start_time": "2024-03-28T14:18:59.227248Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synaptic_matrix = load_npz(\"adult_data/synaptic_matrix_sparse.npz\")\n",
    "\n",
    "model = FullAdultModel(\n",
    "    synaptic_matrix,\n",
    "    decision_making_vector,\n",
    "    root_id_to_index.shape[0],\n",
    "    NUM_CONNECTOME_PASSES,\n",
    "    batch_size=batch_size,\n",
    "    dtype=dtype,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fa2f7661646a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:22:54.362080Z",
     "start_time": "2024-03-28T14:19:58.045941Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 67.08 GiB. GPU 0 has a total capacity of 7.58 GiB of which 6.99 GiB is free. Process 129168 has 27.52 MiB memory in use. Including non-PyTorch memory, this process has 478.00 MiB memory in use. Of the allocated memory 268.14 MiB is allocated by PyTorch, and 23.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m out \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, labels)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Calculate run parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 67.08 GiB. GPU 0 has a total capacity of 7.58 GiB of which 6.99 GiB is free. Process 129168 has 27.52 MiB memory in use. Including non-PyTorch memory, this process has 478.00 MiB memory in use. Of the allocated memory 268.14 MiB is allocated by PyTorch, and 23.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "from from_retina_to_connectome_utils import create_csr_input\n",
    "\n",
    "\n",
    "if wandb_:\n",
    "    wandb.init(project=\"adult_connectome\", config=model_config)\n",
    "\n",
    "model.train()\n",
    "\n",
    "results = initialize_results_df()\n",
    "probabilities = []\n",
    "accuracies = []\n",
    "already_selected = []\n",
    "running_loss = 0.0\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "iterations = debug_length if debugging else len(training_videos) // batch_size\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    batch_files, already_selected = select_random_videos(\n",
    "        training_videos, batch_size, already_selected\n",
    "    )\n",
    "    labels = paths_to_labels(batch_files)\n",
    "    batch_sequences = image_paths_to_sequences(batch_files)\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "\n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        # rendered sequences are in RGB; move it to 0-1 for better training\n",
    "        rendered_sequence = torch.div(rendered_sequence, 255)\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(\n",
    "            LayerActivity(simulation, network.connectome, keepref=True)\n",
    "        )\n",
    "\n",
    "    if wandb_ and i % wandb_images_every == 0:\n",
    "        la_0 = hex_to_square_grid(\n",
    "            layer_activations[0][cell_type_plot].squeeze()[-last_good_frame].cpu().numpy()\n",
    "            ),\n",
    "        log_images_to_wandb(batch_sequences[0], rendered_sequences[0], la_0, batch_files[0], frame=last_good_frame, cell_type=cell_type_plot)\n",
    "\n",
    "    voronoi_averages_df = compute_voronoi_averages(\n",
    "        layer_activations, classification, DECODING_CELLS, last_good_frame=last_good_frame\n",
    "    )\n",
    "    # normalize column wise (except last column) using apply\n",
    "    values_cols = voronoi_averages_df.columns != \"index_name\"\n",
    "    voronoi_averages_df.loc[:, values_cols] = voronoi_averages_df.loc[:, values_cols].apply(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min()), axis=0\n",
    "        )\n",
    "\n",
    "    activation_df = from_retina_to_connectome(\n",
    "        voronoi_averages_df, classification, root_id_to_index\n",
    "    )\n",
    "    del layer_activations, rendered_sequences, rendered_sequence, simulation\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if wandb_:\n",
    "        wandb.watch(model, criterion, log=\"all\", log_freq=20)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # inputs = create_csr_input(activation_df)\n",
    "    inputs = torch.tensor(activation_df.values, dtype=dtype, device=DEVICE)\n",
    "    labels = torch.tensor(labels, dtype=dtype, device=DEVICE).unsqueeze(1)\n",
    "\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate run parameters\n",
    "    predictions, labels_cpu, correct = predictions_and_corrects_from_model_results(out, labels)\n",
    "    results = update_results_df(results, batch_files, predictions, labels_cpu, correct)\n",
    "    running_loss += update_running_loss(loss, inputs)\n",
    "    total += labels.shape[0]\n",
    "    total_correct += correct.sum()\n",
    "\n",
    "    if wandb_:\n",
    "        log_running_stats_to_wandb(0, i, running_loss, total_correct, total, results)\n",
    "\n",
    "print(f\"Finished training with loss {running_loss / total} and accuracy {total_correct / total}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33a081fe1b9a883e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T09:37:12.123162Z",
     "start_time": "2024-03-28T09:37:11.886793Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1960 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m batch_sequences \u001b[38;5;241m=\u001b[39m load_custom_sequences(batch_files)  \u001b[38;5;66;03m# Load and preprocess the video sequences\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming receptors is a function that processes your sequences\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m rendered_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mreceptors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m layer_activations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rendered_sequence \u001b[38;5;129;01min\u001b[39;00m rendered_sequences:\n",
      "File \u001b[0;32m~/Desktop/doctorat/connectome/flyvision/rendering/eye.py:116\u001b[0m, in \u001b[0;36mBoxEye.__call__\u001b[0;34m(self, sequence, ftype, hex_sample)\u001b[0m\n\u001b[1;32m    111\u001b[0m samples, frames, height, width \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sequence, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# auto-moving to GPU in case default tensor is cuda but passed\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# sequence is not for convenience\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_frame_size \u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([height, width]))\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# to rescale to the minimum frame size\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m ttf\u001b[38;5;241m.\u001b[39mresize(\n\u001b[1;32m    121\u001b[0m         sequence, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_frame_size\u001b[38;5;241m.\u001b[39mtolist(), antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "already_selected_validation = []\n",
    "# Assuming batch_size is defined\n",
    "for _ in tqdm(range(len(validation_videos) // batch_size)):\n",
    "    batch_files, already_selected_validation = select_random_videos(validation_videos, batch_size, already_selected_validation)\n",
    "\n",
    "    labels = paths_to_labels(batch_files)  # Convert paths to labels\n",
    "    batch_sequences = load_custom_sequences(batch_files)  # Load and preprocess the video sequences\n",
    "    \n",
    "    # Assuming receptors is a function that processes your sequences\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "    \n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(LayerActivity(simulation, network.connectome, keepref=True))\n",
    "        \n",
    "    del rendered_sequences, simulation\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Preparing the data for the model, similar to training\n",
    "    inputs, labels = from_retina_to_model(layer_activations, labels, DECODING_CELLS, last_good_frame, classification, root_id_to_index)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).unsqueeze(-1).float()\n",
    "        \n",
    "        with autocast(device_type):\n",
    "            predictions = model(inputs)\n",
    "            # Assuming your criterion and evaluation metrics are defined similarly to training\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            # Calculate other metrics if necessary, e.g., accuracy\n",
    "            \n",
    "            # Log validation metrics to WandB\n",
    "            wandb.log({\"validation_loss\": loss.item()})\n",
    "            # Log other metrics similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93414a83f7bbd3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dabc4d2827d8cc4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When cuda breaks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba39b3687e323bec",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for eudald: \n",
      "[sudo] password for eudald: \n"
     ]
    }
   ],
   "source": [
    "!sudo rmmod nvidia_uvm\n",
    "!sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0185e185",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

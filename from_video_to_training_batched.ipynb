{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-06T19:23:45.812316Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import device, cuda, autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import flyvision\n",
    "from flyvision_ans import DECODING_CELLS\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "from from_retina_to_connectome_funcs import from_retina_to_model, get_decision_making_neurons\n",
    "from graph_models import GNNModel\n",
    "from from_video_to_training_batched_funcs import get_files_from_directory, select_random_videos, paths_to_labels, \\\n",
    "    load_custom_sequences\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "torch.manual_seed(42)\n",
    "batch_size = 8\n",
    "last_good_frame = 2\n",
    "\n",
    "TRAINING_DATA_DIR = \"easy_videos\"\n",
    "TESTING_DATA_DIR = \"easyval_videos\"\n",
    "\n",
    "debugging = True\n",
    "\n",
    "NUM_CONNECTOME_PASSES=5"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# init stuff\n",
    "extent, kernel_size = 15, 13\n",
    "decision_making_vector = get_decision_making_neurons()\n",
    "receptors = flyvision.rendering.BoxEye(extent=extent, kernel_size=kernel_size)\n",
    "network_view = flyvision.NetworkView(flyvision.results_dir / \"opticflow/000/0000\")\n",
    "network = network_view.init_network(chkpt=\"best_chkpt\")\n",
    "classification = pd.read_csv(\"adult_data/classification_clean.csv\")\n",
    "root_id_to_index = pd.read_csv(\"adult_data/root_id_to_index.csv\")\n",
    "\n",
    "all_videos = get_files_from_directory(TRAINING_DATA_DIR)\n",
    "all_validation_videos = get_files_from_directory(TESTING_DATA_DIR)\n",
    "dt = 1 / 100 # some random parameter from flyvision"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "63b101e44d143f78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = GNNModel(\n",
    "    num_node_features=1, \n",
    "    decision_making_vector=decision_making_vector,\n",
    "    num_passes=NUM_CONNECTOME_PASSES\n",
    ").to(DEVICE)\n",
    "lr = .01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4fce80a3502cf3c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wandb.init(project=\"adult_connectome\", config={\"learning_rate\": lr, \"batch_size\": batch_size})\n",
    "\n",
    "already_selected = []\n",
    "for i in tqdm(range(len(all_videos) // batch_size)):\n",
    "    batch_files, already_selected = select_random_videos(all_videos, batch_size, already_selected)\n",
    "    labels = paths_to_labels(batch_files)  # Assuming this function converts paths to labels\n",
    "    batch_sequences = load_custom_sequences(batch_files)\n",
    "    \n",
    "    # Assuming receptors is a function that processes your sequences\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "    \n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(LayerActivity(simulation, network.connectome, keepref=True))\n",
    "        \n",
    "    del rendered_sequences, simulation\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Assuming from_retina_to_model prepares your data for the model, including labels\n",
    "    inputs, labels = from_retina_to_model(\n",
    "        layer_activations, labels, DECODING_CELLS, last_good_frame, classification, root_id_to_index\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model.train()\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    # Update the code to process the entire batch at once\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE).unsqueeze(-1).float() \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast(device_type):\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, labels)\n",
    "    \n",
    "    wandb.log({\"loss\": loss.item()})\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if debugging and i == 9:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f8fa2f7661646a93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "already_selected_validation = []\n",
    "# Assuming batch_size is defined\n",
    "for _ in tqdm(range(len(all_validation_videos) // batch_size)):\n",
    "    batch_files, already_selected_validation = select_random_videos(all_validation_videos, batch_size, already_selected_validation)\n",
    "\n",
    "    labels = paths_to_labels(batch_files)  # Convert paths to labels\n",
    "    batch_sequences = load_custom_sequences(batch_files)  # Load and preprocess the video sequences\n",
    "    \n",
    "    # Assuming receptors is a function that processes your sequences\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "    \n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(LayerActivity(simulation, network.connectome, keepref=True))\n",
    "        \n",
    "    del rendered_sequences, simulation\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Preparing the data for the model, similar to training\n",
    "    inputs, labels = from_retina_to_model(layer_activations, labels, DECODING_CELLS, last_good_frame, classification, root_id_to_index)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE).unsqueeze(-1).float()\n",
    "        \n",
    "        with autocast(device_type):\n",
    "            predictions = model(inputs)\n",
    "            # Assuming your criterion and evaluation metrics are defined similarly to training\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            # Calculate other metrics if necessary, e.g., accuracy\n",
    "            \n",
    "            # Log validation metrics to WandB\n",
    "            wandb.log({\"validation_loss\": loss.item()})\n",
    "            # Log other metrics similarly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33a081fe1b9a883e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e93414a83f7bbd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

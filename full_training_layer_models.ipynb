{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:40:02.816615Z",
     "start_time": "2024-03-28T14:39:58.709963Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import device, cuda, autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from random import sample\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "import flyvision\n",
    "from flyvision_ans import DECODING_CELLS\n",
    "from flyvision.utils.activity_utils import LayerActivity\n",
    "from from_image_to_video import image_paths_to_sequences\n",
    "from from_retina_to_connectome_funcs import from_retina_to_model, get_cell_type_indices, compute_voronoi_averages, from_retina_to_connectome\n",
    "from logs_to_wandb import log_images_to_wandb, log_running_stats_to_wandb\n",
    "from from_video_to_training_batched_funcs import get_files_from_directory, select_random_videos, paths_to_labels, \\\n",
    "    load_custom_sequences\n",
    "from from_retina_to_connectome_utils import (\n",
    "    hex_to_square_grid,\n",
    "    initialize_results_df,\n",
    "    predictions_and_corrects_from_model_results,\n",
    "    update_results_df,\n",
    "    update_running_loss,\n",
    "    get_decision_making_neurons,\n",
    "    vector_to_one_hot,\n",
    ")\n",
    "from adult_models import FullAdultModel\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    'ignore',\n",
    "    message='invalid value encountered in cast',\n",
    "    category=RuntimeWarning,\n",
    "    module='wandb.sdk.data_types.image'\n",
    ")\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "dtype = torch.float32\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "# device_type = \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "sparse_layout = torch.sparse_coo\n",
    "\n",
    "TRAINING_DATA_DIR = \"images/easy_v2\"\n",
    "TESTING_DATA_DIR = \"images/easy_images\"\n",
    "VALIDATION_DATA_DIR = \"images/easyval_images\"\n",
    "\n",
    "debugging = False\n",
    "debug_length = 1000\n",
    "validation_length = 50\n",
    "wandb_ = True\n",
    "wandb_images_every = 100\n",
    "small = True\n",
    "small_length = 2000\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "\n",
    "dropout = .1\n",
    "max_lr = 0.01\n",
    "base_lr = 0.0001\n",
    "weight_decay = 0.0001\n",
    "NUM_CONNECTOME_PASSES = 8\n",
    "\n",
    "use_one_cycle_lr = False\n",
    "\n",
    "model_config = {\n",
    "    \"debugging\": debugging,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dropout\": dropout,\n",
    "    \"base_lr\": base_lr,\n",
    "    \"max_lr\": max_lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"num_connectome_passes\": NUM_CONNECTOME_PASSES,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b101e44d143f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:18:59.226154Z",
     "start_time": "2024-03-28T14:18:54.651619Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init stuff\n",
    "extent, kernel_size = 15, 13\n",
    "decision_making_vector = get_decision_making_neurons(dtype)\n",
    "receptors = flyvision.rendering.BoxEye(extent=extent, kernel_size=kernel_size)\n",
    "network_view = flyvision.NetworkView(flyvision.results_dir / \"opticflow/000/0000\")\n",
    "network = network_view.init_network(chkpt=\"best_chkpt\")\n",
    "classification = pd.read_csv(\"adult_data/classification_clean.csv\")\n",
    "root_id_to_index = pd.read_csv(\"adult_data/root_id_to_index.csv\")\n",
    "dt = 1 / 100 # some parameter from flyvision\n",
    "last_good_frame = 2\n",
    "cell_type_plot = \"TmY18\"\n",
    "\n",
    "cell_type_indices = get_cell_type_indices(classification, root_id_to_index, DECODING_CELLS)\n",
    "\n",
    "training_videos = get_files_from_directory(TRAINING_DATA_DIR)\n",
    "test_videos = get_files_from_directory(TESTING_DATA_DIR)\n",
    "validation_videos = get_files_from_directory(TESTING_DATA_DIR)\n",
    "\n",
    "if small:\n",
    "    training_videos = sample(training_videos, small_length)\n",
    "    test_videos = sample(test_videos, small_length)\n",
    "    validation_videos = sample(validation_videos, int(small_length / 5))\n",
    "\n",
    "if len(training_videos) == 0:\n",
    "    print(\"I can't find any training images or videos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fce80a3502cf3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:18:59.238988Z",
     "start_time": "2024-03-28T14:18:59.227248Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synaptic_matrix = load_npz(\"adult_data/synaptic_matrix_sparse.npz\")\n",
    "one_hot_decision_making = vector_to_one_hot(\n",
    "    decision_making_vector, dtype, sparse_layout\n",
    ").to(DEVICE)\n",
    "\n",
    "model = FullAdultModel(\n",
    "    synaptic_matrix,\n",
    "    one_hot_decision_making,\n",
    "    NUM_CONNECTOME_PASSES,\n",
    "    dtype=dtype,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fa2f7661646a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:22:54.362080Z",
     "start_time": "2024-03-28T14:19:58.045941Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meudald\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/eudald/Desktop/doctorat/connectome/wandb/run-20240418_231736-z5cv7rnd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eudald/adult_connectome/runs/z5cv7rnd' target=\"_blank\">crimson-morning-99</a></strong> to <a href='https://wandb.ai/eudald/adult_connectome' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eudald/adult_connectome' target=\"_blank\">https://wandb.ai/eudald/adult_connectome</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eudald/adult_connectome/runs/z5cv7rnd' target=\"_blank\">https://wandb.ai/eudald/adult_connectome/runs/z5cv7rnd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [3:01:46<00:00,  5.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with loss 5.30792955799e+28 and accuracy 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if wandb_:\n",
    "    wandb.init(project=\"adult_connectome\", config=model_config)\n",
    "\n",
    "model.train()\n",
    "\n",
    "results = initialize_results_df()\n",
    "probabilities = []\n",
    "accuracies = []\n",
    "already_selected = []\n",
    "running_loss = 0.0\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "iterations = debug_length if debugging else len(training_videos) // batch_size\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    batch_files, already_selected = select_random_videos(\n",
    "        training_videos, batch_size, already_selected\n",
    "    )\n",
    "    labels = paths_to_labels(batch_files)\n",
    "    batch_sequences = image_paths_to_sequences(batch_files)\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "\n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        # rendered sequences are in RGB; move it to 0-1 for better training\n",
    "        rendered_sequence = torch.div(rendered_sequence, 255)\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(\n",
    "            LayerActivity(simulation, network.connectome, keepref=True)\n",
    "        )\n",
    "\n",
    "    if wandb_ and i % wandb_images_every == 0:\n",
    "        la_0 = hex_to_square_grid(\n",
    "            layer_activations[0][cell_type_plot].squeeze()[-last_good_frame].cpu().numpy()\n",
    "            ),\n",
    "        log_images_to_wandb(batch_sequences[0], rendered_sequences[0], la_0, batch_files[0], frame=last_good_frame, cell_type=cell_type_plot)\n",
    "\n",
    "    voronoi_averages_df = compute_voronoi_averages(\n",
    "        layer_activations, classification, DECODING_CELLS, last_good_frame=last_good_frame\n",
    "    )\n",
    "    # normalize column wise (except last column)\n",
    "    values_cols = voronoi_averages_df.columns != \"index_name\"\n",
    "    voronoi_averages_df.loc[:, values_cols] = voronoi_averages_df.loc[:, values_cols].apply(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min()), axis=0\n",
    "        )\n",
    "\n",
    "    activation_df = from_retina_to_connectome(\n",
    "        voronoi_averages_df, classification, root_id_to_index\n",
    "    )\n",
    "    del layer_activations, rendered_sequences, rendered_sequence, simulation\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs = torch.tensor(activation_df.values, dtype=dtype, device=DEVICE).to_sparse(\n",
    "        layout=sparse_layout\n",
    "    )\n",
    "    labels = torch.tensor(labels, dtype=dtype, device=DEVICE)\n",
    "\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, labels)\n",
    "    # scaler.scale(loss).backward()\n",
    "    # scaler.step(optimizer)\n",
    "    # scaler.update()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate run parameters\n",
    "    predictions, labels_cpu, correct = predictions_and_corrects_from_model_results(out, labels)\n",
    "    results = update_results_df(results, batch_files, predictions, labels_cpu, correct)\n",
    "    running_loss += update_running_loss(loss, inputs)\n",
    "    total += labels.shape[0]\n",
    "    total_correct += correct.sum()\n",
    "\n",
    "    if wandb_:\n",
    "        log_running_stats_to_wandb(0, i, running_loss, total_correct, total, results)\n",
    "\n",
    "print(f\"Finished training with loss {running_loss / total} and accuracy {total_correct / total}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a081fe1b9a883e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T09:37:12.123162Z",
     "start_time": "2024-03-28T09:37:11.886793Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:03<02:55,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4639311281903427e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:07<02:51,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.444757998579572e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:10<02:47,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3978831607726631e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:14<02:43,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3787176700515676e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:17<02:39,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4185685971495152e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:21<02:36,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:24<02:33,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4385053256433898e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:28<02:29,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:32<02:26,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:35<02:22,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:39<02:19,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:42<02:15,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:46<02:10,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:49<02:08,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4814516468715036e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:53<02:04,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:57<02:01,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:00<01:57,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [01:04<01:52,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [01:07<01:50,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4263331900725547e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:11<01:46,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:14<01:43,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4435393539393594e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [01:18<01:40,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [01:21<01:36,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [01:25<01:32,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [01:29<01:29,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4123818700710356e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [01:32<01:25,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4473418771859164e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:36<01:21,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.442428330618242e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [01:39<01:18,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4154992139221672e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:43<01:14,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4577770839562963e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:46<01:10,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:50<01:07,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [01:53<01:04,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.448585179001663e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [01:57<01:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [02:01<00:56,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.3709921418301583e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [02:04<00:53,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [02:08<00:49,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4142123027489078e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [02:11<00:46,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4200233705060174e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [02:15<00:42,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [02:18<00:39,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4220221488411625e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [02:22<00:35,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4622584047410816e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:25<00:32,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [02:29<00:28,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.442885600355889e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [02:33<00:24,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4251050693413527e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [02:36<00:21,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.354377266702138e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [02:40<00:17,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4410740231651899e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [02:43<00:14,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [02:47<00:10,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [02:50<00:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4535989980831753e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [02:54<00:03,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.435180281348937e+29, Validation Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:57<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "already_selected_validation = []\n",
    "validation_results = initialize_results_df()\n",
    "validation_iterations = validation_length if validation_length is not None else len(validation_videos) // batch_size\n",
    "for _ in tqdm(range(validation_iterations)):\n",
    "    batch_files, already_selected_validation = select_random_videos(validation_videos, batch_size, already_selected_validation)\n",
    "\n",
    "    labels = paths_to_labels(batch_files)\n",
    "    batch_sequences = image_paths_to_sequences(batch_files)\n",
    "    rendered_sequences = receptors(batch_sequences)\n",
    "    layer_activations = []\n",
    "    for rendered_sequence in rendered_sequences:\n",
    "        simulation = network.simulate(rendered_sequence[None], dt)\n",
    "        layer_activations.append(LayerActivity(simulation, network.connectome, keepref=True))\n",
    "\n",
    "    voronoi_averages_df = compute_voronoi_averages(\n",
    "        layer_activations, classification, DECODING_CELLS, last_good_frame=last_good_frame\n",
    "    )\n",
    "    # normalize column wise (except last column)\n",
    "    values_cols = voronoi_averages_df.columns != \"index_name\"\n",
    "    voronoi_averages_df.loc[:, values_cols] = voronoi_averages_df.loc[:, values_cols].apply(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min()), axis=0\n",
    "        )\n",
    "\n",
    "    activation_df = from_retina_to_connectome(\n",
    "        voronoi_averages_df, classification, root_id_to_index\n",
    "    )\n",
    "    del layer_activations, rendered_sequences, rendered_sequence, simulation\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval() \n",
    "\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(activation_df.values, dtype=dtype, device=DEVICE).to_sparse(\n",
    "            layout=sparse_layout\n",
    "        )\n",
    "        labels = torch.tensor(labels, dtype=dtype, device=DEVICE)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        predictions, batch_labels_cpu, correct = predictions_and_corrects_from_model_results(outputs, labels)\n",
    "        validation_results = update_results_df(validation_results, batch_files, predictions, batch_labels_cpu, correct)\n",
    "        running_loss += update_running_loss(loss, inputs)\n",
    "        total += batch_labels_cpu.shape[0]\n",
    "        total_correct += correct.sum().item()\n",
    "\n",
    "print(\n",
    "    f\"Validation Loss: {running_loss / total}, \"\n",
    "    f\"Validation Accuracy: {total_correct / total}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e93414a83f7bbd3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>True label</th>\n",
       "      <th>Is correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/easy_images/yellow/img2_15_10_26.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Image  Prediction  True label  \\\n",
       "0  images/easy_images/yellow/img2_15_10_26.png         1.0         1.0   \n",
       "\n",
       "  Is correct  \n",
       "0          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabc4d2827d8cc4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When cuda breaks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba39b3687e323bec",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for eudald: \n",
      "[sudo] password for eudald: \n"
     ]
    }
   ],
   "source": [
    "!sudo rmmod nvidia_uvm\n",
    "!sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0185e185",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_model_summary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary(model, torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape), show_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_model_summary import summary\n",
    "\n",
    "print(summary(model, torch.zeros(inputs.shape), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af231b6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero entries (trainable parameters): 3871467\n",
      "Shape of the sparse tensor: torch.Size([3871467])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_nnz' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_nnz' is only available for these backends: [Meta, SparseCPU, SparseCUDA, SparseMeta, SparseCsrCPU, SparseCsrCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:1387 [kernel]\nSparseCUDA: registered at aten/src/ATen/RegisterSparseCUDA.cpp:1573 [kernel]\nSparseMeta: registered at aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1135 [kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterSparseCsrCUDA.cpp:1276 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_4.cpp:13162 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of non-zero entries (trainable parameters):\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mconnectome\u001b[38;5;241m.\u001b[39mshared_weights\u001b[38;5;241m.\u001b[39mnumel())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the sparse tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mconnectome\u001b[38;5;241m.\u001b[39mshared_weights\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of parameters (non-zero entries):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nnz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_nnz' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_nnz' is only available for these backends: [Meta, SparseCPU, SparseCUDA, SparseMeta, SparseCsrCPU, SparseCsrCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nSparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:1387 [kernel]\nSparseCUDA: registered at aten/src/ATen/RegisterSparseCUDA.cpp:1573 [kernel]\nSparseMeta: registered at aten/src/ATen/RegisterSparseMeta.cpp:249 [kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1135 [kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterSparseCsrCUDA.cpp:1276 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:17434 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_4.cpp:13162 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# Correctly print number of non-zero entries\n",
    "print(\"Number of non-zero entries (trainable parameters):\", model.connectome.shared_weights.numel())\n",
    "print(\"Shape of the sparse tensor:\", model.connectome.shared_weights.shape)\n",
    "print(\"Number of parameters (non-zero entries):\", model.connectome.shared_weights._nnz())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eeef86c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([134191, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9088f10",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "model.adul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

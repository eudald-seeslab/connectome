{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import config\n",
    "from utils import get_image_paths\n",
    "\n",
    "from graph_models import FullGraphModel\n",
    "from from_retina_to_connectome_utils import (\n",
    "    select_random_images,\n",
    "    paths_to_labels,\n",
    "    initialize_results_df,\n",
    "    clean_model_outputs,\n",
    "    update_results_df,\n",
    "    update_running_loss,\n",
    ")\n",
    "from scipy.sparse import load_npz\n",
    "from complete_training_funcs import (\n",
    "    get_voronoi_cells,\n",
    "    import_images,\n",
    "    process_images,\n",
    "    get_voronoi_averages,\n",
    "    assign_cell_type,\n",
    "    get_neuron_activations,\n",
    "    get_side_decision_making_vector,\n",
    ")\n",
    "from torch_geometric.data import Data, Batch\n",
    "from wandb_utils import WandBLogger\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"invalid value encountered in cast\",\n",
    "    category=RuntimeWarning,\n",
    "    module=\"wandb.sdk.data_types.image\",\n",
    ")\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "training_images_dir = config.TRAINING_DATA_DIR\n",
    "small = config.small\n",
    "small_length = config.small_length\n",
    "ommatidia_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "# todo: move elsewhere\n",
    "right_visual = pd.read_csv(\"adult_data/right_filtered.csv\").drop(\n",
    "    columns=[\"side\", \"x\"]\n",
    ")\n",
    "neuron_indices, voronoi_indices = get_voronoi_cells(right_visual)\n",
    "right_visual[\"voronoi_indices\"] = neuron_indices\n",
    "right_visual[\"cell_type\"] = right_visual.apply(assign_cell_type, axis=1)\n",
    "right_visual = right_visual.drop(columns=[\"y\", \"z\"])\n",
    "right_root_ids = pd.read_csv(\"adult_data/right_root_id_to_index.csv\")\n",
    "training_images = get_image_paths(training_images_dir, False, small_length)\n",
    "\n",
    "decision_making_vector = get_side_decision_making_vector(right_root_ids, \"right\")\n",
    "synaptic_matrix = load_npz(\"adult_data/right_synaptic_matrix.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullGraphModel(\n",
    "    input_shape=synaptic_matrix.shape[0],\n",
    "    num_connectome_passes=config.NUM_CONNECTOME_PASSES,\n",
    "    decision_making_vector=decision_making_vector,\n",
    "    log_transform_weights=config.log_transform_weights,\n",
    "    batch_size=config.batch_size,\n",
    "    dtype=config.dtype,\n",
    "    retina_connection=False\n",
    ").to(config.DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.base_lr)\n",
    "\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "# train\n",
    "results = initialize_results_df()\n",
    "already_selected = []\n",
    "running_loss, total_correct, total = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meudald\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e05ee73d29e4038a5b8e221ff740a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112425700007911, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/eudald/Desktop/doctorat/connectome/wandb/run-20240502_202712-tq64bt6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eudald/adult_complete/runs/tq64bt6i' target=\"_blank\">pretty-glade-5</a></strong> to <a href='https://wandb.ai/eudald/adult_complete' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eudald/adult_complete' target=\"_blank\">https://wandb.ai/eudald/adult_complete</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eudald/adult_complete/runs/tq64bt6i' target=\"_blank\">https://wandb.ai/eudald/adult_complete/runs/tq64bt6i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [42:11<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with loss 46232.714590812844 and accuracy 0.503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958316ab692144659ea875a99de100a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>iteration</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.503</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>iteration</td><td>32</td></tr><tr><td>loss</td><td>46232.71459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-glade-5</strong> at: <a href='https://wandb.ai/eudald/adult_complete/runs/tq64bt6i' target=\"_blank\">https://wandb.ai/eudald/adult_complete/runs/tq64bt6i</a><br/> View project at: <a href='https://wandb.ai/eudald/adult_complete' target=\"_blank\">https://wandb.ai/eudald/adult_complete</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240502_202712-tq64bt6i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandBLogger(\"adult_complete\")\n",
    "wandb_logger.initialize()\n",
    "\n",
    "model.train()\n",
    "iterations = (\n",
    "    config.debug_length\n",
    "    if config.debugging\n",
    "    else len(training_images) // config.batch_size\n",
    ")\n",
    "for i in tqdm(range(iterations)):\n",
    "    batch_files, already_selected = select_random_images(\n",
    "        training_images, config.batch_size, already_selected\n",
    "    )\n",
    "    labels = paths_to_labels(batch_files)\n",
    "    imgs = import_images(batch_files)\n",
    "    processed_imgs = process_images(imgs, voronoi_indices)\n",
    "    voronoi_averages = get_voronoi_averages(processed_imgs)\n",
    "    neuron_activations = pd.concat(\n",
    "        [get_neuron_activations(right_visual, a) for a in voronoi_averages],\n",
    "        axis=1,\n",
    "    )\n",
    "    activation_df = (\n",
    "        right_root_ids.merge(\n",
    "            neuron_activations, left_on=\"root_id\", right_index=True, how=\"left\"\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .set_index(\"index\")\n",
    "        .drop(columns=[\"root_id\"])\n",
    "    )\n",
    "    edges = torch.tensor(\n",
    "        np.array([synaptic_matrix.row, synaptic_matrix.col]),\n",
    "        # Note: the edges need to be specificaly int64\n",
    "        dtype=torch.int64,\n",
    "    )\n",
    "    weights = torch.tensor(synaptic_matrix.data, dtype=config.dtype)\n",
    "    activation_tensor = torch.tensor(activation_df.values, dtype=config.dtype)\n",
    "    graph_list_ = []\n",
    "    for j in range(activation_tensor.shape[1]):\n",
    "        # Shape [num_nodes, 1], one feature per node\n",
    "        node_features = activation_tensor[:, j].unsqueeze(1)\n",
    "        graph = Data(\n",
    "            x=node_features,\n",
    "            edge_index=edges,\n",
    "            edge_attr=weights,\n",
    "            y=labels[j],\n",
    "            device=config.DEVICE,\n",
    "        )\n",
    "        graph_list_.append(graph)\n",
    "\n",
    "    inputs = Batch.from_data_list(graph_list_).to(config.DEVICE)\n",
    "    labels = torch.tensor(labels, dtype=config.dtype).to(config.DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate run parameters\n",
    "    outputs, predictions, labels_cpu, correct = clean_model_outputs(out, labels)\n",
    "    results = update_results_df(\n",
    "        results, batch_files, outputs, predictions, labels_cpu, correct\n",
    "    )\n",
    "    running_loss += update_running_loss(loss, inputs)\n",
    "    total += config.batch_size\n",
    "    total_correct += correct.sum()\n",
    "\n",
    "    wandb_logger.log_metrics(i, running_loss, total_correct, total, results)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Finished training with loss {running_loss / total} and accuracy {total_correct / total}\"\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "wandb_logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coses a fer:\n",
    "- canviar les cel·les de voronoi a cada batch\n",
    "- fer múltipes passades per veure la mateixa imatge amb més d'una tesselació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

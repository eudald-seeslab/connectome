{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:10.443650381Z",
     "start_time": "2024-02-02T16:08:06.722907340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from retina_to_connectome import get_activation_tensor, get_batch_voronoi_averages\n",
    "\n",
    "\n",
    "from flyvis.examples.flyvision_ans import DECODING_CELLS\n",
    "\n",
    "last_good_frame = 8"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get data\n",
    "activations_dir = \"flyvis/parsed_objects\"\n",
    "activations = np.load(os.path.join(activations_dir, \"decoding_activations.npy\"), allow_pickle=True)\n",
    "classification = pd.read_csv(\"adult_data/classification.csv\")\n",
    "\n",
    "# remove duplicated root_ids\n",
    "classification = classification.drop_duplicates(subset='root_id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:12.078660353Z",
     "start_time": "2024-02-02T16:08:10.443645880Z"
    }
   },
   "id": "a1466ccb6d444b07",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:10<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "avgs_dict = {}\n",
    "for cell_type in tqdm(DECODING_CELLS):\n",
    "    number_of_cells = len(classification[classification[\"cell_type\"] == cell_type])\n",
    "    if number_of_cells > 0:\n",
    "        activation_tensor = get_activation_tensor(activations, cell_type, last_frame=last_good_frame) / 255\n",
    "        avgs_dict[cell_type] = get_batch_voronoi_averages(activation_tensor, n_centers=number_of_cells)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:22.994877768Z",
     "start_time": "2024-02-02T16:08:12.082151241Z"
    }
   },
   "id": "8a91bc55a5c9604c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def voronoi_averages_to_df(dict_with_voronoi_averages):\n",
    "    dfs = []\n",
    "    for key, matrix in dict_with_voronoi_averages.items():\n",
    "        df = pd.DataFrame(matrix.transpose())\n",
    "        df['index_name'] = key\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all the DataFrames into one\n",
    "    return pd.concat(dfs, axis=0, ignore_index=True)\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:28.269595524Z",
     "start_time": "2024-02-02T16:08:28.223839770Z"
    }
   },
   "id": "16ba36ae0792bc06",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result_df = voronoi_averages_to_df(avgs_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:28.327991824Z",
     "start_time": "2024-02-02T16:08:28.249391908Z"
    }
   },
   "id": "66d6df94b20c7524",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract cell types and activations\n",
    "cell_types = result_df.iloc[:, -1]  # Last column for cell type\n",
    "activations = result_df.iloc[:, :-1]  # Exclude the last column\n",
    "\n",
    "# Create a dictionary to hold shuffled root_ids for each cell type\n",
    "root_id_mapping = {}\n",
    "\n",
    "# Populate the dictionary with shuffled root_ids for each cell type\n",
    "for cell_type, group in classification.groupby(\"cell_type\"):\n",
    "    # Shuffle the root_ids within each group\n",
    "    shuffled_root_ids = group['root_id'].sample(frac=1).values\n",
    "    root_id_mapping[cell_type] = shuffled_root_ids\n",
    "\n",
    "# Function to assign root_ids to each row in result_df based on cell type and available root_ids\n",
    "def assign_root_ids(row):\n",
    "    cell_type = row.iloc[-1]  # Get cell type from the last column\n",
    "    # Get the list of shuffled root_ids for this cell type\n",
    "    root_ids = root_id_mapping[cell_type]\n",
    "    # Assign a root_id from the list, ensuring we don't exceed the list's length\n",
    "    # The index in the list is the count of occurrences of this cell type so far, modulo the number of available root_ids\n",
    "    root_id_index = row.name % len(root_ids)  # row.name is the index of the row in the dataframe\n",
    "    return root_ids[root_id_index]\n",
    "\n",
    "# Apply the function to result_df, creating a new 'root_id' column\n",
    "result_df['root_id'] = result_df.apply(assign_root_ids, axis=1)\n",
    "\n",
    "# Remove duplicated root_ids\n",
    "result_df = result_df.drop_duplicates(subset='root_id')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:35.023866028Z",
     "start_time": "2024-02-02T16:08:34.107380352Z"
    }
   },
   "id": "aa33a3309a235441",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = pd.merge(\n",
    "    classification.drop(\n",
    "        columns=[\"flow\", \"super_class\", \"class\", \"sub_class\", \n",
    "                 \"hemibrain_type\", \"hemilineage\", \"side\", \"nerve\"]), \n",
    "    result_df.drop(columns=[result_df.columns[-2]]), on='root_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:38.422438520Z",
     "start_time": "2024-02-02T16:08:38.232840838Z"
    }
   },
   "id": "7b9d37652bf3d75a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from adult_models_helpers import get_synapse_df\n",
    "synapse_df = get_synapse_df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:41.190286576Z",
     "start_time": "2024-02-02T16:08:38.572771830Z"
    }
   },
   "id": "ea5873de3ea67ca8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: Identify Common Neurons\n",
    "# Unique root_ids in merged_df\n",
    "neurons_merged = pd.unique(activation_df['root_id'])\n",
    "\n",
    "# Unique root_ids in synapse_df (both pre and post)\n",
    "neurons_synapse_pre = pd.unique(synapse_df['pre_root_id'])\n",
    "neurons_synapse_post = pd.unique(synapse_df['post_root_id'])\n",
    "neurons_synapse = np.unique(np.concatenate([neurons_synapse_pre, neurons_synapse_post]))\n",
    "\n",
    "# Common neurons\n",
    "common_neurons = np.intersect1d(neurons_merged, neurons_synapse)\n",
    "\n",
    "# Step 2: Filter synapse_df\n",
    "# Keep only rows with both pre and post root_ids in common_neurons\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Filter synapse_df to include only rows with both pre and post root_ids in common_neurons\n",
    "filtered_synapse_df = synapse_df[\n",
    "    synapse_df['pre_root_id'].isin(common_neurons) & synapse_df['post_root_id'].isin(common_neurons)\n",
    "]\n",
    "\n",
    "# Map neuron root_ids to matrix indices\n",
    "root_id_to_index = {root_id: index for index, root_id in enumerate(common_neurons)}\n",
    "\n",
    "# Convert root_ids in filtered_synapse_df to matrix indices\n",
    "pre_indices = filtered_synapse_df['pre_root_id'].map(root_id_to_index).values\n",
    "post_indices = filtered_synapse_df['post_root_id'].map(root_id_to_index).values\n",
    "\n",
    "# Use syn_count as the data for the non-zero elements of the matrix\n",
    "data = filtered_synapse_df['syn_count'].values\n",
    "\n",
    "# Create a sparse matrix in COO format\n",
    "synaptic_matrix_sparse = coo_matrix(\n",
    "    (data, (pre_indices, post_indices)),\n",
    "    shape=(len(common_neurons), len(common_neurons)),\n",
    "    dtype=np.int64  # or np.float32/np.float64 if memory issue persists\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:43.462857632Z",
     "start_time": "2024-02-02T16:08:42.042187252Z"
    }
   },
   "id": "4b9b0fc3eb3b1c75",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Neurons in merged_df\n",
    "neurons_merged = set(activation_df['root_id'])\n",
    "\n",
    "# Neurons in synaptic_matrix_sparse\n",
    "neurons_synaptic = set(common_neurons)  # common_neurons was used to build the synaptic matrix\n",
    "\n",
    "# Neurons in merged_df not in synaptic_matrix\n",
    "missing_in_synaptic = neurons_merged - neurons_synaptic\n",
    "\n",
    "# Neurons in synaptic_matrix not in merged_df\n",
    "missing_in_merged = neurons_synaptic - neurons_merged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:46.768942813Z",
     "start_time": "2024-02-02T16:08:46.720924521Z"
    }
   },
   "id": "ac4670dc90dd0a2c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from adult_models_helpers import get_synapse_df\n",
    "\n",
    "\n",
    "class AdultConnectomeNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        adjacency_matrix,\n",
    "        neuron_count: int,\n",
    "        general_config: Dict[str, Union[int, float, str, bool]],\n",
    "    ):\n",
    "        super(AdultConnectomeNetwork, self).__init__()\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Convert the adjacency matrix to a PyTorch sparse tensor once in the initialization\n",
    "        self.adjacency_matrix_coo = adjacency_matrix.tocoo()\n",
    "        self.adj_matrix_sparse = torch.sparse_coo_tensor(\n",
    "            torch.tensor(\n",
    "                [self.adjacency_matrix_coo.row, self.adjacency_matrix_coo.col]\n",
    "            ),\n",
    "            torch.FloatTensor(self.adjacency_matrix_coo.data),\n",
    "            torch.Size(self.adjacency_matrix_coo.shape),\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        self.connectome_layer_number = general_config[\"CONNECTOME_LAYER_NUMBER\"]\n",
    "\n",
    "        # Initialize the shared weights for the connectome layers\n",
    "        self.shared_weights = self.initialize_sparse_weights(\n",
    "            adjacency_matrix, neuron_count\n",
    "        )\n",
    "        self.shared_bias = nn.Parameter(torch.ones(neuron_count))\n",
    "\n",
    "    def initialize_sparse_weights(self, adjacency_matrix, neuron_count):\n",
    "        # Generate random weights for existing connections, ensuring the tensor is on the same device\n",
    "        weights = torch.rand(\n",
    "            len(adjacency_matrix.data), device=self.device\n",
    "        )  # Specify device here\n",
    "\n",
    "        # Create sparse weights tensor, ensuring indices are on the same device\n",
    "        indices = torch.tensor(\n",
    "            [adjacency_matrix.row, adjacency_matrix.col], device=self.device\n",
    "        )  # Specify device here\n",
    "        sparse_weights = torch.sparse_coo_tensor(\n",
    "            indices, weights, (neuron_count, neuron_count), device=self.device\n",
    "        )\n",
    "\n",
    "        return nn.Parameter(sparse_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Use the pre-converted adjacency matrix in sparse format\n",
    "        adj_matrix = self.adj_matrix_sparse.to(x.device)\n",
    "\n",
    "        # Pass the input through the layer with shared weights\n",
    "        for _ in range(self.connectome_layer_number):\n",
    "            # Apply the mask from the adjacency matrix to the shared weights\n",
    "            masked_weights = torch.sparse.mm(adj_matrix, self.shared_weights).to(x.device)\n",
    "\n",
    "            # Do the forward pass using sparse matrix multiplication\n",
    "            x = torch.sparse.mm(masked_weights, x) + self.shared_bias.unsqueeze(0)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:47.815228251Z",
     "start_time": "2024-02-02T16:08:47.811795705Z"
    }
   },
   "id": "3727145dbfc1970b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activation_df = activation_df[activation_df['root_id'].isin(list(root_id_to_index.keys()))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:50.906254396Z",
     "start_time": "2024-02-02T16:08:50.880761592Z"
    }
   },
   "id": "ee8423219793cadf",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45370/925662702.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  torch.tensor(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 808.00 MiB. GPU 0 has a total capacty of 7.58 GiB of which 476.00 MiB is free. Including non-PyTorch memory, this process has 6.95 GiB memory in use. Of the allocated memory 6.74 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 21>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m adult_connectome_network\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Now, you can feed the entire batch of samples into the network\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m output_activations \u001B[38;5;241m=\u001B[39m \u001B[43madult_connectome_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivation_tensor\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mAdultConnectomeNetwork.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# Pass the input through the layer with shared weights\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnectome_layer_number):\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# Apply the mask from the adjacency matrix to the shared weights\u001B[39;00m\n\u001B[0;32m---> 61\u001B[0m     masked_weights \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43madj_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshared_weights\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;66;03m# Do the forward pass using sparse matrix multiplication\u001B[39;00m\n\u001B[1;32m     64\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39mmm(masked_weights, x) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_bias\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 808.00 MiB. GPU 0 has a total capacty of 7.58 GiB of which 476.00 MiB is free. Including non-PyTorch memory, this process has 6.95 GiB memory in use. Of the allocated memory 6.74 GiB is allocated by PyTorch, and 53.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "activation_data = activation_df.drop(columns=[\"root_id\", \"cell_type\"])\n",
    "\n",
    "# Convert the activation data DataFrame to a numpy array, then to a PyTorch tensor\n",
    "activation_tensor = torch.tensor(activation_data.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Transpose the tensor to have the sample dimension first (sample_size x neuron_count)\n",
    "activation_tensor = activation_tensor.t()\n",
    "\n",
    "sample_count, neuron_count = activation_tensor.shape\n",
    "general_config = {\"CONNECTOME_LAYER_NUMBER\": 2}\n",
    "\n",
    "adult_connectome_network = AdultConnectomeNetwork(synaptic_matrix_sparse, neuron_count, general_config)\n",
    "adult_connectome_network.to(device)\n",
    "\n",
    "# Now, you can feed the entire batch of samples into the network\n",
    "output_activations = adult_connectome_network(activation_tensor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:08:58.084829716Z",
     "start_time": "2024-02-02T16:08:55.433743292Z"
    }
   },
   "id": "9502729772032235",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils import flush_cuda_memory\n",
    "\n",
    "flush_cuda_memory()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T14:21:49.052533048Z",
     "start_time": "2024-02-02T14:21:48.973473992Z"
    }
   },
   "id": "3db8404555c0d8bd",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27d60c774fb6d65c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

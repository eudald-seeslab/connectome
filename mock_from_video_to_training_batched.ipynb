{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:28:59.615525Z",
     "start_time": "2024-04-02T12:28:55.246720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import device, cuda, autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from conv_models import AlternativeCNN\n",
    "from from_video_to_training_batched_funcs import get_files_from_directory, select_random_videos, paths_to_labels, load_custom_sequences\n",
    "from logs_to_wandb import log_original_to_wandb\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    'ignore',\n",
    "    message='invalid value encountered in cast',\n",
    "    category=RuntimeWarning,\n",
    "    module='wandb.sdk.data_types.image'\n",
    ")\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "torch.manual_seed(42)\n",
    "batch_size = 50\n",
    "last_good_frame = 2\n",
    "\n",
    "TRAINING_DATA_DIR = \"easy_videos\"\n",
    "TESTING_DATA_DIR = \"easyval_videos\"\n",
    "\n",
    "debugging = False\n",
    "debug_length = 50\n",
    "wandb_ = True\n",
    "wandb_images_every = 10\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "channel_sizes = [16, 32, 64]\n",
    "mult_size = .5\n",
    "channel_sizes = [int(a * mult_size) for a in channel_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_videos = get_files_from_directory(TRAINING_DATA_DIR)\n",
    "all_validation_videos = get_files_from_directory(TESTING_DATA_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:28:59.678866Z",
     "start_time": "2024-04-02T12:28:59.617004Z"
    }
   },
   "id": "63b101e44d143f78",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = AlternativeCNN(\n",
    "    out_channels_1 = channel_sizes[0],\n",
    "    out_channels_2 = channel_sizes[1],\n",
    "    out_channels_3 = channel_sizes[2]\n",
    ").to(DEVICE)\n",
    "lr = .01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T12:29:00.066492Z",
     "start_time": "2024-04-02T12:28:59.679825Z"
    }
   },
   "id": "4fce80a3502cf3c7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33meudald\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/eudald/Desktop/doctorat/connectome/wandb/run-20240402_142901-g6qg11hl</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/eudald/binary_classification/runs/g6qg11hl' target=\"_blank\">celestial-blaze-19</a></strong> to <a href='https://wandb.ai/eudald/binary_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/eudald/binary_classification' target=\"_blank\">https://wandb.ai/eudald/binary_classification</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/eudald/binary_classification/runs/g6qg11hl' target=\"_blank\">https://wandb.ai/eudald/binary_classification/runs/g6qg11hl</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [26:19<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3257832202306461, Accuracy: 0.9530357142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [26:16<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.14785569478269844, Accuracy: 0.9804761904761905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "iterations = debug_length if debugging else len(all_videos) // batch_size\n",
    "# Start wandb run\n",
    "if wandb_:\n",
    "    wandb.init(project='binary_classification')\n",
    "    data_table = wandb.Table(columns=[\"Predictions\", \"True Labels\"])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    already_selected = []\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in tqdm(range(iterations)):\n",
    "        batch_files, already_selected = select_random_videos(\n",
    "            all_videos, batch_size, already_selected\n",
    "        )\n",
    "        labels = paths_to_labels(batch_files)\n",
    "        batch_sequences = load_custom_sequences(batch_files)\n",
    "        batch_sequences = batch_sequences[:, -last_good_frame, :, :] \n",
    "        if wandb_ and i % wandb_images_every == 0:\n",
    "            log_original_to_wandb(batch_sequences[0], batch_files[0])\n",
    "        \n",
    "        # Add channel dimension and normalize\n",
    "        batch_sequences = np.divide(batch_sequences[:, None, :, :], 255)\n",
    "\n",
    "        # Ensure the data is in tensor form and on the correct device\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float).to(DEVICE)\n",
    "        batch_sequences_tensor = torch.tensor(batch_sequences, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "        # Create the dataset and dataloader\n",
    "        dataset = TensorDataset(batch_sequences_tensor, labels_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        for inputs, batch_labels in dataloader:\n",
    "            inputs.to(DEVICE)\n",
    "            batch_labels.to(DEVICE)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Forward pass\n",
    "            with autocast(device_type):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), batch_labels)\n",
    "    \n",
    "            # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                # Calculate the running loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                predictions = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predictions == batch_labels).sum().item()\n",
    "                \n",
    "                if wandb_:\n",
    "                    predictions = torch.sigmoid(outputs).squeeze().detach().cpu()\n",
    "                    batch_labels_cpu = batch_labels.detach().cpu()\n",
    "                    for pred, label in zip(predictions, batch_labels_cpu):\n",
    "                        data_table.add_data(pred.item(), label.item())\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        if wandb_:\n",
    "            wandb.log({\n",
    "                'epoch': epoch,\n",
    "                'loss': running_loss / total,\n",
    "                'accuracy': correct / total,\n",
    "            })\n",
    "    wandb.log({\"predictions_vs_labels\": data_table})\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / total}, Accuracy: {correct / total}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:21:39.067899Z",
     "start_time": "2024-04-02T12:29:00.067992Z"
    }
   },
   "id": "a3b94263294e5262",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [04:20<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.516447865045988, Validation Accuracy: 0.5089743589743589\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "\n",
    "# Create a table for logging validation predictions and true labels to wandb\n",
    "if wandb_:\n",
    "    val_data_table = wandb.Table(columns=[\"Predictions\", \"True Labels\"])\n",
    "\n",
    "# No need to iterate over epochs in the validation phase\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i in tqdm(range(len(all_validation_videos) // batch_size)):\n",
    "        batch_files, _ = select_random_videos(\n",
    "            all_validation_videos, batch_size, already_selected=[]\n",
    "        )\n",
    "        labels = paths_to_labels(batch_files)\n",
    "        batch_sequences = load_custom_sequences(batch_files)\n",
    "        batch_sequences = batch_sequences[:, -last_good_frame, :, :]\n",
    "        batch_sequences = np.divide(batch_sequences[:, None, :, :], 255)\n",
    "\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.float).to(DEVICE)\n",
    "        batch_sequences_tensor = torch.tensor(batch_sequences, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "        dataset = TensorDataset(batch_sequences_tensor, labels_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        for inputs, batch_labels in dataloader:\n",
    "            inputs, batch_labels = inputs.to(DEVICE), batch_labels.to(DEVICE)\n",
    "            \n",
    "            # Forward pass only to get logits/output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), batch_labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = torch.sigmoid(outputs).squeeze() > 0.5\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predictions == batch_labels).sum().item()\n",
    "\n",
    "            if wandb_:\n",
    "                predictions = torch.sigmoid(outputs).squeeze().detach().cpu()\n",
    "                batch_labels_cpu = batch_labels.detach().cpu()\n",
    "                for pred, label in zip(predictions, batch_labels_cpu):\n",
    "                    val_data_table.add_data(pred.item(), label.item())\n",
    "\n",
    "# Log validation metrics to wandb\n",
    "if wandb_:\n",
    "    wandb.log({\n",
    "        'val_loss': running_loss / total,\n",
    "        'val_accuracy': correct / total,\n",
    "        \"val_predictions_vs_labels\": val_data_table\n",
    "    })\n",
    "\n",
    "print(f'Validation Loss: {running_loss / total}, Validation Accuracy: {correct / total}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T13:28:59.493751Z",
     "start_time": "2024-04-02T13:24:38.154711Z"
    }
   },
   "id": "e925cb0d6cfa7f80",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "19a61ca797bb8b81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import multiprocessing\n",
    "\n",
    "from configs import config\n",
    "from connectome.core.data_processing import DataProcessor\n",
    "from connectome.core.graph_models import FullGraphModel\n",
    "from utils.model_inspection_funcs import sample_images\n",
    "from scripts.no_training import process_image_without_deciding\n",
    "\n",
    "num_test_pairs = 500\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor(\n",
    "    neurons=config.neurons,\n",
    "    voronoi_criteria=config.voronoi_criteria,\n",
    "    random_synapses=config.random_synapses,\n",
    "    log_transform_weights=config.log_transform_weights,\n",
    ")\n",
    "\n",
    "model = FullGraphModel(\n",
    "    input_shape=data_processor.number_of_synapses,\n",
    "    num_connectome_passes=config.NUM_CONNECTOME_PASSES,\n",
    "    decision_making_vector=data_processor.decision_making_vector,\n",
    "    batch_size=config.batch_size,\n",
    "    dtype=config.dtype,\n",
    "    edge_weights=data_processor.synaptic_matrix.data,\n",
    "    device=config.DEVICE,\n",
    "    num_classes=len(config.CLASSES),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horrible data stuff\n",
    "checkpoint = torch.load(\n",
    "    \"models/n_all_v_R7_r_False_lr_0.003_p_4_2024-05-27 21:45.pth\", map_location=\"cpu\"\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "connections = (\n",
    "    pd.read_csv(\n",
    "        \"adult_data/connections.csv\",\n",
    "        dtype={\n",
    "            \"pre_root_id\": \"string\",\n",
    "            \"post_root_id\": \"string\",\n",
    "            \"syn_count\": np.int32,\n",
    "        },\n",
    "    )\n",
    "    .groupby([\"pre_root_id\", \"post_root_id\"])\n",
    "    .sum(\"syn_count\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "connections[\"weight\"] = model.connectome.edge_weight_multiplier.detach()\n",
    "right_root_ids = data_processor.root_ids\n",
    "all_neurons = (\n",
    "    pd.read_csv(\"../../adult_data/classification_clean.csv\")\n",
    "    .merge(right_root_ids, on=\"root_id\")\n",
    "    .fillna(\"Unknown\")\n",
    ")\n",
    "neuron_data = pd.read_csv(\n",
    "    \"../../adult_data/right_visual_positions_selected_neurons.csv\",\n",
    "    dtype={\"root_id\": \"string\"},\n",
    ").drop(columns=[\"x\", \"y\", \"z\", \"PC1\", \"PC2\"])\n",
    "data_cols = [\"x_axis\", \"y_axis\"]\n",
    "all_coords = pd.read_csv(\"../../adult_data/all_coords_clean.csv\", dtype={\"root_id\": \"string\"})\n",
    "rational_cell_types = pd.read_csv(\"../../adult_data/rational_cell_types.csv\")\n",
    "all_neurons[\"decision_making\"] = np.where(\n",
    "    all_neurons[\"cell_type\"].isin(rational_cell_types[\"cell_type\"].values.tolist()),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "all_neurons[\"root_id\"] = all_neurons[\"root_id\"].astype(\"string\")\n",
    "\n",
    "neurons_in_coords = all_neurons.merge(all_coords, on=\"root_id\", how=\"right\")[\n",
    "    [\"root_id\", \"cell_type\"]\n",
    "].fillna(\"Unknown\")\n",
    "\n",
    "# Set all cell_types with less than \"n\" samples to \"others\"\n",
    "n = 1\n",
    "\n",
    "counts = neurons_in_coords[\"cell_type\"].value_counts()\n",
    "\n",
    "small_categories = counts[counts < n].index\n",
    "neurons_in_coords[\"cell_type\"] = neurons_in_coords[\"cell_type\"].apply(\n",
    "    lambda x: \"others\" if x in small_categories else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passes = 4\n",
    "base_dir = \"images/one_colour\"\n",
    "sub_dirs = [str(i) for i in range(1, 10)]\n",
    "\n",
    "sampled_images = sample_images(base_dir, sub_dirs, num_test_pairs)\n",
    "\n",
    "tasks = [\n",
    "    (img, neuron_data, connections, all_coords, num_passes)\n",
    "    for img in sampled_images\n",
    "]\n",
    "result_tuples = process_map(\n",
    "    process_image_without_deciding, tasks, max_workers=multiprocessing.cpu_count() - 2, chunksize=1\n",
    ")\n",
    "dms = dict(result_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dms)\n",
    "df = data.T\n",
    "df[\"num_points\"] = [int(a.split(\"_\")[1]) for a in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = {0: 1, 1: .5, 2: .4, 3: .2, 4: 0}\n",
    "def get_normalized_response(n, total):\n",
    "    acts = []\n",
    "    for i in range(1, total):\n",
    "        dist = abs(n - i)\n",
    "        if dist in model_response.keys():\n",
    "            acts.append(model_response[dist])\n",
    "        else:\n",
    "            acts.append(0)\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df.groupby(\"num_points\").mean()\n",
    "# normalize all columns to 0-1\n",
    "means = (means - means.min()) / (means.max() - means.min())\n",
    "# remove columns with missing data\n",
    "means = means.dropna(axis=1)\n",
    "for i in range(1, 10):\n",
    "    means[f\"tuning_curve_{i}\"] = get_normalized_response(i, 10)\n",
    "temp = means.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(\"neuron_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del tasks, result_tuples, dms, data, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(temp[temp[1] == temp.max(axis=1)]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_neurons_tuned_to_i(df, i, method=\"pearson\"):\n",
    "    col_name = f\"tuning_curve_{i}\"\n",
    "    \n",
    "    tuned = (df[df[i] == df.max(axis=1)]).T\n",
    "    print(tuned.shape[1])\n",
    "    if tuned.shape[1] > 12000:\n",
    "        return \"Too many neurons tuned to this curve\"\n",
    "    correlations = tuned.corr(method)[col_name].sort_values(ascending=False)\n",
    "    # remove \"tune_curve_i\" from the list\n",
    "    correlations = correlations.drop(col_name)\n",
    "    top_correlations = correlations[correlations > 0.9]\n",
    "\n",
    "    return neurons_in_coords.merge(\n",
    "        top_correlations, left_index=True, right_index=True\n",
    "    ).sort_values(by=col_name, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns = {}\n",
    "for i in range(1, 10):\n",
    "    tns[f\"num_{i}\"] = top_neurons_tuned_to_i(temp, i, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcs = {}\n",
    "for name, tn in tns.items():\n",
    "    if type(tn) != str:\n",
    "        vcs[name] = tn[\"cell_type\"].value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if some cell types are in all the top neurons\n",
    "common = set(vcs[\"num_3\"].index)\n",
    "for name, vc in vcs.items():\n",
    "    if type(vc) != str:\n",
    "        print(name)\n",
    "        common = common.intersection(set(vc.index))\n",
    "        print(common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcs[\"num_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcs[\"num_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns[\"num_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns[\"num_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns[\"num_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns[\"num_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T07:59:05.718391Z",
     "start_time": "2024-03-03T07:59:05.714352Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autocast, device, cuda\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from graph_models import GNNModel\n",
    "\n",
    "\n",
    "device_type = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "DEVICE = device(device_type)\n",
    "batch_size = 10\n",
    "last_good_frame = 8"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get data\n",
    "activations_dir = \"flyvis/parsed_objects\"\n",
    "activations = np.load(os.path.join(activations_dir, \"decoding_activations.npy\"), allow_pickle=True)\n",
    "# labels = np.load(os.path.join(activations_dir, \"decoding_labels.npy\"), allow_pickle=True)\n",
    "# toy labels as a tensor with all 1\n",
    "labels = torch.ones(activations.shape[0], dtype=torch.long, device=DEVICE)\n",
    "classification = pd.read_csv(\"adult_data/classification.csv\").drop_duplicates(subset='root_id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T07:59:13.683911Z",
     "start_time": "2024-03-03T07:59:12.364839Z"
    }
   },
   "id": "a1466ccb6d444b07",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eudald/Desktop/doctorat/connectome/venv/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "100%|██████████| 34/34 [00:10<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from retina_to_connectome_funcs import create_root_id_mapping\n",
    "from flyvis.examples.flyvision_ans import DECODING_CELLS\n",
    "from connectome_model_preparation import prepare_connectome_input, compute_voronoi_averages, LAST_GOOD_FRAME, \\\n",
    "    get_synaptic_matrix, get_rational_neurons\n",
    "\n",
    "result_df = compute_voronoi_averages(\n",
    "    activations, classification, DECODING_CELLS, last_good_frame=LAST_GOOD_FRAME\n",
    ")\n",
    "\n",
    "# Create a dictionary to hold shuffled root_ids for each cell type\n",
    "root_id_mapping = create_root_id_mapping(classification)\n",
    "\n",
    "def assign_root_ids(row):\n",
    "    cell_type = row.iloc[-1]\n",
    "    root_ids = root_id_mapping[cell_type]\n",
    "    return root_ids[row.name % len(root_ids)]\n",
    "\n",
    "# Apply the function to result_df, creating a new 'root_id' column\n",
    "result_df[\"root_id\"] = result_df.apply(assign_root_ids, axis=1)\n",
    "\n",
    "# Remove duplicated root_ids\n",
    "result_df = result_df.drop_duplicates(subset=\"root_id\")\n",
    "\n",
    "activation_df = pd.merge(\n",
    "    classification.drop(\n",
    "        columns=[\n",
    "            \"flow\",\n",
    "            \"super_class\",\n",
    "            \"class\",\n",
    "            \"sub_class\",\n",
    "            \"hemibrain_type\",\n",
    "            \"hemilineage\",\n",
    "            \"side\",\n",
    "            \"nerve\",\n",
    "        ]\n",
    "    ),\n",
    "    result_df.drop(columns=[result_df.columns[-2]]),\n",
    "    on=\"root_id\",\n",
    "    how=\"left\",\n",
    ").fillna(0)\n",
    "synaptic_matrix_sparse, root_id_to_index = get_synaptic_matrix(activation_df)\n",
    "activation_df = activation_df[\n",
    "    activation_df[\"root_id\"].isin(list(root_id_to_index.keys()))\n",
    "]\n",
    "activation_data = activation_df.drop(columns=[\"root_id\", \"cell_type\"])\n",
    "\n",
    "# fixme: this should not be here\n",
    "decision_making_vector = get_rational_neurons(root_id_to_index, activation_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T07:59:43.793211Z",
     "start_time": "2024-03-03T07:59:28.183546Z"
    }
   },
   "id": "236f8bd6296bd55d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "temp = load_npz(\"adult_data/synaptic_matrix_sparse.npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T08:09:14.422105Z",
     "start_time": "2024-03-03T08:09:14.246356Z"
    }
   },
   "id": "89a7ad0eb8f5355",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "edges = torch.tensor(\n",
    "    np.array([synaptic_matrix_sparse.row, synaptic_matrix_sparse.col]),\n",
    "    dtype=torch.long,\n",
    "    device=DEVICE,\n",
    ")\n",
    "activation_tensor = torch.tensor(\n",
    "    activation_data.values, dtype=torch.float16, device=DEVICE\n",
    ")\n",
    "\n",
    "# move the decision-making vector to the device\n",
    "decision_making_vector = torch.tensor(\n",
    "    decision_making_vector, dtype=torch.float16, device=DEVICE\n",
    ").detach()\n",
    "\n",
    "# Correctly set node features for each graph\n",
    "graph_list = []\n",
    "for i in range(\n",
    "    activation_tensor.shape[1]\n",
    "):  # Iterate over samples, ensuring the second dimension is the sample dimension\n",
    "    node_features = activation_tensor[:, i].unsqueeze(\n",
    "        1\n",
    "    )  # Shape [num_nodes, 1], one feature per node\n",
    "    graph = Data(\n",
    "        x=node_features.to(device), edge_index=edges, y=labels[i]\n",
    "    )  # Create a graph for each sample\n",
    "    graph_list.append(graph)\n",
    "\n",
    "# DataLoader to handle batches of graphs\n",
    "loader = DataLoader(graph_list, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "725b7990aca2f78f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.03it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "edges = torch.tensor(np.array([synaptic_matrix_sparse.row, synaptic_matrix_sparse.col]), dtype=torch.long, device=DEVICE)\n",
    "activation_tensor = torch.tensor(activation_data.values, dtype=torch.float16, device=DEVICE)\n",
    "\n",
    "# move the decision-making vector to the device\n",
    "decision_making_vector = torch.tensor(decision_making_vector, dtype=torch.float16, device=DEVICE).detach()\n",
    "\n",
    "# Correctly set node features for each graph\n",
    "graph_list = []\n",
    "for i in range(activation_tensor.shape[1]):  # Iterate over samples, ensuring the second dimension is the sample dimension\n",
    "    node_features = activation_tensor[:, i].unsqueeze(1)  # Shape [num_nodes, 1], one feature per node\n",
    "    graph = Data(x=node_features.to(DEVICE), edge_index=edges, y=labels[i])  # Create a graph for each sample\n",
    "    graph_list.append(graph)\n",
    "\n",
    "# DataLoader to handle batches of graphs\n",
    "loader = DataLoader(graph_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = GNNModel(num_node_features=1, decision_making_vector=decision_making_vector).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "model.train()\n",
    "for batch_idx, batch in tqdm(enumerate(loader)):\n",
    "    batch = batch.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast(device_type):\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y.unsqueeze(-1).float())    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T16:40:41.116128Z",
     "start_time": "2024-03-01T16:40:39.808853Z"
    }
   },
   "id": "4f726ab91ee1f4cb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "1. Literature review to identify the \"thinking\" neurons\n",
    "2. Identify these neurons in the classification dataframe and create a class_labels tensor\n",
    "3. Train the model with the class_labels tensor\n",
    "4. Check model accuracy and weber ratio\n",
    "5. Try with other model architectures, specially with a one-hot encoding for each neuron type to simulate different neurons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acc97de0c76463cf"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36fda2cb163b38ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kenyon Cells (KC): KCab, KCapbp-m, KCapbp-ap1, KCapbp-ap2\n",
    "T4/T5 Neurons: These are involved in motion detection and possibly could be implicated in processing visual information related to numerosity. The neurons you've listed include T4a, T4b, T4c, T4d, T5a, T5b, T5c, T5d.\n",
    "Central Complex Neurons: These are involved in a variety of integrative brain functions which could include decision-making processes. The neurons from your list include C2, C3.\n",
    "torch.unique(batch.y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b841d74ff7cc601"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:04:46.941314Z",
     "start_time": "2024-03-01T09:04:46.937250Z"
    }
   },
   "id": "30a10e83166f413c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:05:14.205394Z",
     "start_time": "2024-03-01T09:05:14.201268Z"
    }
   },
   "id": "53aef8a6447394d7",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "df78fe0069fea8df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

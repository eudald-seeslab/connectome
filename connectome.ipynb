{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:26:31.619525400Z",
     "start_time": "2023-09-01T08:26:25.491832800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from torch import nn, optim, device, cuda\n",
    "import torch\n",
    "\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import logging\n",
    "import wandb\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from data_parser import adj_matrix, nodes\n",
    "from image_parser import train_loader, test_loader, debug_loader\n",
    "from utils import log_training_images\n",
    "\n",
    "from models import CombinedModel\n",
    "from model_config_manager import ModelConfigManager\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:26:53.327178Z",
     "start_time": "2023-09-01T08:26:53.270549300Z"
    }
   },
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(\"config.yml\"))\n",
    "DEBUG = config[\"DEBUG\"]\n",
    "epochs = config[\"EPOCHS\"] if not DEBUG else 2\n",
    "RETINA_MODEL = config[\"RETINA_MODEL\"]\n",
    "images_fraction = config[\"IMAGES_FRACTION\"]\n",
    "continue_training = config[\"CONTINUE_TRAINING\"]\n",
    "saved_model_path = config[\"SAVED_MODEL_PATH\"]\n",
    "model_name = config[\"MODEL_NAME\"]\n",
    "save_every = config[\"SAVE_EVERY\"]\n",
    "layer_number = config[\"LAYER_NUMBER\"]\n",
    "\n",
    "loader = debug_loader if DEBUG else train_loader\n",
    "\n",
    "logger = logging.getLogger(\"training_log\")\n",
    "logger.basicConfig(\n",
    "    filename=\"training_log.log\", \n",
    "    level=logging.DEBUG if DEBUG else logging.INFO, \n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "dev = device(\"cuda\" if cuda.is_available() else \"cpu\")    \n",
    "if dev.type == \"cpu\":\n",
    "    logging.warning(\"WARNING: Running on CPU, so it might be slow\")\n",
    "\n",
    "# Create the ModelConfigManager and load configurations from YAML files\n",
    "config_manager = ModelConfigManager()\n",
    "\n",
    "# Get a specific configuration by model name\n",
    "config_manager.set_model_config(RETINA_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T08:27:04.128296400Z",
     "start_time": "2023-09-01T08:26:56.682068200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33meudald\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.9"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\eudald\\Desktop\\doctorat\\codi\\connectome\\wandb\\run-20230901_102703-ko4gf89i</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/eudald/connectome/runs/ko4gf89i' target=\"_blank\">toasty-river-28</a></strong> to <a href='https://wandb.ai/eudald/connectome' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/eudald/connectome' target=\"_blank\">https://wandb.ai/eudald/connectome</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/eudald/connectome/runs/ko4gf89i' target=\"_blank\">https://wandb.ai/eudald/connectome/runs/ko4gf89i</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_model = CombinedModel(adj_matrix, neurons=nodes, model_config=config_manager.model_config)\n",
    "\n",
    "if continue_training:\n",
    "    # If we want to continue training a saved model\n",
    "    combined_model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "combined_model = combined_model.to(dev)\n",
    "wandb.init(project=\"connectome\", config=config_manager.model_config)\n",
    "tensorboard_writer = SummaryWriter()\n",
    "\n",
    "# Specify the loss function and the optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=0.00001)\n",
    "_ = wandb.watch(combined_model, criterion, log=\"all\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-01T08:27:11.037879100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configurations:\n",
      "Model name: cnn_2\n",
      "Number of layers: 1\n",
      "Output channels: 2\n",
      "Kernel size: 5\n",
      "Stride: 2\n",
      "Padding: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a27b2d5e803548d08fdafb393fa87390"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca86f3f41e3e47d58a6f838eb1b4866d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:00.181036, resuming normal operation.\n",
      "C:\\Users\\eudald\\Desktop\\doctorat\\codi\\connectome\\venv\\Lib\\site-packages\\wandb\\wandb_torch.py:193: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ..\\torch\\csrc\\tensor\\python_tensor.cpp:85.)\n",
      "  check = torch.cuda.FloatTensor(1).fill_(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcadf1d42ef44e11a94663fd2ad2edcb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:07.966611, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.914002, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:01.441976, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84572f187a3247eaad499dd76bf89086"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.117193, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.035804, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:01.558888, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1c462724afc4736b5f527891e1bbe53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:01.589120, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.085581, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d7136ba553645339dff46683bfafc58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:04.041417, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.113916, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c95adaf00e44274a8951d33eb19cb86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.175954, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.100400, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.238663, resuming normal operation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c68b4d317bd440d91b8d7389d539f3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error resolved after 0:00:08.180975, resuming normal operation.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n"
     ]
    }
   ],
   "source": [
    "config_manager.output_model_details()\n",
    "if DEBUG:\n",
    "    logger.warning(\"WARNING: Running on DEBUG mode, so using 10% of the images\")\n",
    "elif images_fraction < 1:\n",
    "    logger.warning(f\"WARNING: Using {images_fraction * 100}% of the images\")\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    running_loss = 0\n",
    "    correct_predictions = 0\n",
    "    # If the model is fast~ish\n",
    "    # for images, labels in train_loader:\n",
    "    for images, labels in tqdm(loader):\n",
    "\n",
    "        # Move images and labels to the device\n",
    "        images, labels = images.to(dev), labels.to(dev)\n",
    "\n",
    "                # Log model architecture to tensorboard\n",
    "        if epoch == 0:\n",
    "            tensorboard_writer.add_graph(combined_model, images)\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = combined_model(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Compute the accuracy\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions = (predicted_labels == labels).sum().item()\n",
    "        accuracy = correct_predictions / len(labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Logs to wandb\n",
    "        wandb.log({\"loss\": loss.item(), \"accuracy\": accuracy, \"epoch\": epoch})\n",
    "        log_training_images(images, labels, outputs)\n",
    "\n",
    "    logger.info(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Save model\n",
    "    if (epoch + 1) % save_every == 0:\n",
    "        torch.save(combined_model.state_dict(), os.path.join(\"models\", f\"model:{RETINA_MODEL}_layers:{layer_number}_epochs:{epoch + 1}_{model_name}.pth\"))\n",
    "        logger.info(f\"Saved model after {epoch + 1} runs\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T20:31:47.444241700Z",
     "start_time": "2023-08-25T20:31:40.488538600Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(combined_model.state_dict(), os.path.join(\"models\", f\"model_{RETINA_MODEL}_{epoch + 1}_epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T05:50:26.110925Z",
     "start_time": "2023-08-29T05:49:40.848133800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/250 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94e88a8022844c42ab0e7fdc16a97633"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test de model\n",
    "correct = 0\n",
    "total = 0\n",
    "test_results_df = pd.DataFrame(columns=[\"Image\", \"Real Label\", \"Predicted Label\", \"Correct Prediction\"])\n",
    "\n",
    "j = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images, labels = images.to(dev), labels.to(dev)\n",
    "        outputs = combined_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        # Convert the tensor values to CPU and numpy\n",
    "        labels_cpu = labels.cpu().numpy()\n",
    "        predicted_cpu = predicted.cpu().numpy()\n",
    "        \n",
    "        # Check if the prediction is correct\n",
    "        correct_predictions = (predicted == labels)\n",
    "        correct_cpu = correct_predictions.cpu().numpy()\n",
    "        \n",
    "        image_names = [a[0] for a in test_loader.dataset.dataset.samples[j * test_loader.batch_size: (j + 1) * test_loader.batch_size]]\n",
    "        j += 1\n",
    "        \n",
    "        batch_df = pd.DataFrame({\n",
    "            \"Image\": image_names,\n",
    "            \"Real Label\": labels_cpu,\n",
    "            \"Predicted Label\": predicted_cpu,\n",
    "            \"Correct Prediction\": correct_cpu.astype(int)\n",
    "        })\n",
    "        \n",
    "        # Append the batch DataFrame to the list\n",
    "        test_results_df = pd.concat([test_results_df, batch_df], ignore_index=True)\n",
    "\n",
    "logger.info(f\"Accuracy on the {total} test images: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T17:21:48.170557500Z",
     "start_time": "2023-08-27T17:21:48.111585400Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m correct_percentage \u001B[38;5;241m=\u001B[39m test_results_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweber_ratio\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrect Prediction\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Plot\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n\u001B[0;32m      9\u001B[0m sns\u001B[38;5;241m.\u001B[39mbarplot(x\u001B[38;5;241m=\u001B[39mcorrect_percentage\u001B[38;5;241m.\u001B[39mindex, y\u001B[38;5;241m=\u001B[39mcorrect_percentage\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeber Ratio\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of correct answers for each Weber ratio\n",
    "test_results_df['yellow'] = test_results_df['Image'].apply(lambda x: x.split('_')[1])\n",
    "test_results_df['blue'] = test_results_df['Image'].apply(lambda x: x.split('_')[2])\n",
    "test_results_df['weber_ratio'] = test_results_df.apply(lambda row: max(int(row['yellow']), int(row['blue'])) / min(int(row['yellow']), int(row['blue'])), axis=1)\n",
    "correct_percentage = test_results_df.groupby('weber_ratio')['Correct Prediction'].mean() * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=correct_percentage.index, y=correct_percentage.values)\n",
    "plt.xlabel('Weber Ratio')\n",
    "plt.ylabel('Percentage of Correct Answers')\n",
    "plt.title('Percentage of Correct Answers for Each Weber Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T05:50:29.859845100Z",
     "start_time": "2023-08-29T05:50:29.802765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(95.3500, device='cuda:0')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
